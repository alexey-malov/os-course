# Вопросы к экзамену

- [Вопросы к экзамену](#вопросы-к-экзамену)
  - [Общие сведения об ОС](#общие-сведения-об-ос)
  - [Процессы/переключение контекста и регистры, режимы процессора](#процессыпереключение-контекста-и-регистры-режимы-процессора)
  - [Память, виртуальная память и MMU, шины](#память-виртуальная-память-и-mmu-шины)
  - [Базовые абстракции ОС: процессы, адресные пространства, файлы](#базовые-абстракции-ос-процессы-адресные-пространства-файлы)
  - [Пользователи, UID/GID и модель прав](#пользователи-uidgid-и-модель-прав)
  - [Адресное пространство и аппаратная защита](#адресное-пространство-и-аппаратная-защита)
  - [Файловые системы: пути, каталоги, операции](#файловые-системы-пути-каталоги-операции)
  - [Базовые понятия: процесс, программа, абстракция ОС, параллелизм](#базовые-понятия-процесс-программа-абстракция-ос-параллелизм)
  - [Создание процессов: UNIX fork/exec и Windows CreateProcess](#создание-процессов-unix-forkexec-и-windows-createprocess)
  - [Идентификаторы и дескрипторы, управление процессами](#идентификаторы-и-дескрипторы-управление-процессами)
  - [Классическая модель потока](#классическая-модель-потока)
  - [Параллелизм и планирование, ресурсы потока](#параллелизм-и-планирование-ресурсы-потока)
  - [Жизненный цикл потоков и базовые примитивы](#жизненный-цикл-потоков-и-базовые-примитивы)
  - [Базовые понятия IPC и синхронизации](#базовые-понятия-ipc-и-синхронизации)
  - [Классические алгоритмы синхронизации](#классические-алгоритмы-синхронизации)
  - [Спинлоки](#спинлоки)
  - [Спинлоки в ядре: IRQ и вытеснение](#спинлоки-в-ядре-irq-и-вытеснение)
  - [Мьютексы: идея и реализация](#мьютексы-идея-и-реализация)
  - [Futex и condition variables](#futex-и-condition-variables)
  - [std::mutex и разновидности мьютексов](#stdmutex-и-разновидности-мьютексов)
  - [FairRWLock и мониторы](#fairrwlock-и-мониторы)
  - [Барьеры синхронизации (phase synchronization), ошибки работы с многопоточностью](#барьеры-синхронизации-phase-synchronization-ошибки-работы-с-многопоточностью)
  - [Планирование процессов, контекст планирования](#планирование-процессов-контекст-планирования)
  - [Виды процессов и их планирование](#виды-процессов-и-их-планирование)
  - [Категории систем и цели планирования](#категории-систем-и-цели-планирования)
  - [Интерактивные системы: Round Robin и приоритеты](#интерактивные-системы-round-robin-и-приоритеты)
  - [Планирование в системах реального времени](#планирование-в-системах-реального-времени)
  - [Политика против механизма, user-level потоки](#политика-против-механизма-user-level-потоки)


## Общие сведения об ОС

- Дайте определение операционной системы и объясните, какие задачи она решает в современном компьютере. ⭐
- Почему прикладные программы обычно не работают напрямую с «железом»? Какие проблемы возникли бы без ОС? ⭐⭐
- Объясните, как ОС управляет ресурсами при многопользовательской работе. Какие типы конфликтов она предотвращает? ⭐⭐
- Что такое мультиплексирование во времени и в пространстве? Приведите по 2 примера каждого. ⭐⭐
- В каких типах устройств ОС может быть не нужна? Приведите примеры и объясните почему. ⭐⭐
- Чем RTOS отличается от «полноценной» ОС общего назначения? В каких областях RTOS критична? ⭐⭐
- Опишите базовую архитектуру ПК (CPU–память–I/O) и роль системной шины в этой модели. ⭐
- Что означает, что ОС «создаёт абстракции»? Приведите пример перехода от «блоков диска» к «файлам». ⭐⭐
- Что такое драйвер устройства и почему драйверы часто выполняются в режиме ядра? ⭐⭐
- Назовите и сравните три способа установки драйверов (пересборка ядра, загрузка при старте, hotplug). ⭐⭐
- Что такое прерывание (interrupt) и зачем оно нужно при вводе-выводе? Опишите путь от устройства до обработчика. ⭐⭐⭐
- Сравните методы I/O: busy waiting, interrupts, DMA — плюсы/минусы и типичные сценарии использования. ⭐⭐⭐
- Опишите процесс загрузки компьютера: что делает BIOS/UEFI, как выбирается загрузчик и что происходит при запуске ядра ОС. ⭐⭐⭐
- Сравните BIOS и UEFI (MBR vs GPT/ESP, ограничения, возможности). Почему UEFI считают «маленькой ОС»? ⭐⭐⭐

## Процессы/переключение контекста и регистры, режимы процессора

- Что такое context switch и почему при нём важно сохранять/восстанавливать состояние процессора? ⭐⭐
- Какие регистры процессора важны для ОС (PC, SP, PSW) и как ОС использует/учитывает их? ⭐⭐
- Чем архитектура процессора отличается от микроархитектуры? Почему ОС в основном «видит» архитектуру? ⭐⭐
- Объясните, что такое конвейер (pipeline) и как он повышает производительность. Какие сложности он создаёт? ⭐⭐⭐
- Что такое суперскалярный процессор и «внеочередное выполнение»? Почему это может быть важно для ОС? ⭐⭐⭐
- Сравните kernel mode и user mode: какие инструкции/возможности доступны в каждом режиме и почему? ⭐⭐
- Что такое системный вызов (syscall) и чем он отличается от обычного вызова функции? Опишите общий механизм «trap в ядро». ⭐⭐⭐
- Какие бывают аппаратные traps (кроме syscall)? Как ОС может реагировать на исключительные ситуации? ⭐⭐

## Память, виртуальная память и MMU, шины

- Как ОС управляет памятью при одновременной работе нескольких программ? Какие цели преследуются (справедливость/защита/безопасность)? ⭐⭐
- Что такое виртуальная память и зачем она нужна? Опишите идею «RAM как кэш для диска/SSD». ⭐⭐
- Какова роль MMU? Что означает «преобразование виртуальных адресов в физические»? ⭐⭐⭐
- Что такое кэш CPU (L1/L2/L3)? Объясните термины cache hit и cache miss и влияние на производительность. ⭐⭐
- Приведите примеры кэширования в ОС (не в железе) и объясните, почему это ускоряет систему. ⭐⭐
- Сравните HDD и SSD: как устроены, почему HDD медленнее при случайном доступе, и что усложняет запись в SSD. ⭐⭐
- Что такое «шина» в архитектуре компьютера? Почему современные системы используют несколько шин вместо одной? ⭐⭐
- Чем PCIe принципиально отличается от старых параллельных общих шин (PCI/ISA)? Как масштабирование по линиям влияет на скорость? ⭐⭐⭐

## Базовые абстракции ОС: процессы, адресные пространства, файлы

- Почему в ОС вообще нужны абстракции (процессы/адресные пространства/файлы), и какие проблемы «железа» они скрывают от программиста? ⭐⭐
- Чем «программа» отличается от «процесса», и какие атрибуты превращают код на диске в выполняющийся процесс? ⭐
- Как адресное пространство помогает одновременно в удобстве программирования и в безопасности? ⭐⭐
- Приведите пример: какая одна и та же операция может выглядеть «как работа с файлом», но на самом деле быть работой с устройством или IPC? Объясните идею унификации. ⭐⭐
- Какие последствия для дизайна ОС возникают из того, что процесс и файл — ключевые универсальные абстракции почти во всех ОС? ⭐⭐⭐
- Что именно хранит ОС о процессе в «таблице процессов», и зачем там нужны значения регистров и позиции в файлах? ⭐⭐
- Какие ресурсы (кроме памяти) обычно «прикреплены» к процессу, и что должно случиться с ними при завершении процесса? ⭐⭐
- Опишите, что должно произойти при приостановке и последующем возобновлении процесса, чтобы программа «ничего не заметила». ⭐⭐
- Как вы объясните различие между состоянием «спит», «выполняется», «остановлен», «зомби» с точки зрения ОС и родителя процесса? ⭐⭐
- Почему процессы часто называют «контейнерами выполнения», и в каком смысле это похоже/не похоже на контейнеры уровня Docker? ⭐⭐⭐
- Какие выводы о системе можно сделать по списку процессов `ps aux`: что искать в USER/PID/STAT/COMMAND? ⭐
- Чем отличаются VSZ/VIRT и RSS/RES, и почему «много VIRT» не всегда означает «проблема с памятью»? ⭐⭐
- Как интерпретировать %CPU в `top` на многоядерной машине: когда 100% — это «всё» и когда — «одно ядро»? ⭐⭐
- Что означает load average, и почему он может быть высоким даже при низком %CPU? ⭐⭐⭐
- Как бы вы нашли «подозрительный» процесс, который редко использует CPU, но постоянно держит диск занятым? Какие поля/инструменты помогут? ⭐⭐⭐
- Почему в UNIX-подобных системах естественно возникает дерево процессов? Что даёт модель «родитель–ребёнок»? ⭐⭐
- Сравните: IPC через каналы (pipes), через файлы и через сокеты — в чём различие по модели использования и по стоимости? ⭐⭐⭐
- Что такое сигнал: чем он принципиально отличается от «сообщения» IPC, и почему его сравнивают с прерываниями? ⭐⭐
- Придумайте сценарий, где сигнал — хороший механизм (например, таймер/ошибка), и сценарий, где сигнал — плохой выбор и лучше IPC. ⭐⭐⭐
- Что может пойти не так, если процесс «не готов» принимать сигнал (нет обработчика) — почему это иногда полезно, а иногда опасно? ⭐⭐

## Пользователи, UID/GID и модель прав

- Зачем ОС связывает процесс с UID/GID, и как это влияет на доступ к файлам и процессам других пользователей? ⭐⭐
- Чем отличается «пользователь» от «группы» в практическом управлении доступом? Приведите пример политики доступа. ⭐⭐
- Почему root (администратор) — одновременно полезная и опасная концепция? Какие риски она создаёт? ⭐⭐
- Какую информацию можно извлечь из `/etc/passwd`, и почему наличие записи там ещё не означает возможность интерактивного входа? ⭐⭐⭐
- Опишите типичную модель «минимально необходимых прав» и как она реализуется на практике в UNIX через пользователей/группы/права. ⭐⭐⭐
- В чём принципиальная разница между `su` и `sudo` с точки зрения модели безопасности? ⭐⭐
- Почему `su` считается менее безопасным подходом в командах/организациях, и как это связано с паролями и аудитом? ⭐⭐
- Что именно меняется при `su`: какие части «сессии» (окружение, текущий каталог, права) могут вести себя иначе? ⭐⭐⭐
- Зачем `sudo` обычно просит пароль текущего пользователя, а не root? Как это помогает контролю и расследованиям? ⭐⭐
- Опишите сценарий, когда `sudo` может быть опасен при неверной настройке (например, чрезмерные права), и как это предотвратить. ⭐⭐⭐

## Адресное пространство и аппаратная защита

- Что такое адресное пространство процесса, и почему «несколько процессов в памяти» требуют аппаратной поддержки? ⭐⭐
- Как процессор и ОС вместе обеспечивают, что процесс не может читать/писать память другого процесса? (Опишите на уровне идеи.) ⭐⭐⭐
- Что такое режим пользователя и режим ядра, и почему системные вызовы требуют перехода между ними? ⭐⭐
- Почему ранние системы могли обходиться без защиты памяти, и какие компромиссы это накладывало на надёжность? ⭐⭐
- Почему во встраиваемых системах защита памяти иногда отсутствует и сегодня: когда это оправдано, а когда — нет? ⭐⭐⭐
- Объясните идею виртуальной памяти: какие иллюзии она создаёт для процесса и какие задачи решает для ОС? ⭐⭐
- Что такое swap и в каких случаях его использование помогает, а в каких — «убивает» производительность? ⭐⭐
- Как связаны «страницы памяти», подкачка и то, что программа может адресовать больше, чем физическая RAM? ⭐⭐⭐
- Как бы вы интерпретировали вывод `free -h` и `vmstat`: какие поля укажут на активную подкачку и дефицит памяти? ⭐⭐⭐
- Почему виртуальная память упрощает код прикладных программ, а не только «даёт больше памяти»? Приведите пример. ⭐⭐⭐

## Файловые системы: пути, каталоги, операции

- Почему файловая система считается ключевой абстракцией ОС, и какие детали устройств она скрывает? ⭐⭐
- Объясните разницу между абсолютным и относительным путём и роль текущего рабочего каталога процесса. ⭐
- Как устроена иерархия каталогов как «дерево», и какие преимущества даёт по сравнению с одноуровневой директорией? ⭐⭐
- Почему операции `open/read/write/close` считаются «минимальным набором» для работы с данными? Что строится поверх них? ⭐⭐
- Чем отличается удаление файла от удаления каталога (`rm` vs `rmdir`), и почему каталог нельзя удалить, пока он не пуст? ⭐⭐
- Что такое монтирование и почему модель «единое дерево» отличается от «букв дисков» в Windows? ⭐⭐
- Объясните роль `/dev` и смысл «специальных файлов»: что это даёт ОС и приложениям? ⭐⭐
- Что такое pipe в терминах потока данных: почему он выглядит как файл, но ведёт себя иначе? ⭐⭐
- Зачем существуют `/dev/stdout` и `/dev/null`: какие практические сценарии они упрощают? ⭐

## Базовые понятия: процесс, программа, абстракция ОС, параллелизм

- Что такое **процесс** с точки зрения операционной системы, и какие компоненты состояния отличают его от «просто программы на диске»? ⭐
- Объясните разницу между понятиями **программа** и **процесс** на примере одного исполняемого файла, запущенного несколько раз. ⭐
- Почему процесс называют **ключевой абстракцией ОС**, и какие механизмы ОС вокруг него построены? ⭐⭐
- Что означает идея **«виртуального CPU»** для процесса, и за счёт чего ОС создаёт эту иллюзию? ⭐⭐
- Какие ресурсы процесса можно считать **логическими**, а какие — **физическими**, и как ОС разделяет эти уровни? ⭐⭐⭐
- Какие свойства процесса делают его удобной единицей **изоляции и безопасности** в системе? ⭐⭐
- В каких случаях процессы в системе **не являются пользовательскими программами**, а служат инфраструктурой ОС? ⭐⭐
- Объясните, что такое **псевдопараллелизм** на одном ядре и почему пользователь воспринимает его как «одновременность». ⭐
- Чем принципиально отличается псевдопараллелизм от **реального параллелизма** на многоядерной системе? ⭐
- Почему в многозадачной системе **скорость выполнения** отдельного процесса становится плохо предсказуемой? ⭐⭐
- Почему **busy-wait / idle loops** — плохой способ тайминга в ОС с вытесняющей многозадачностью? ⭐⭐
- Какие механизмы нужны системе, чтобы поддерживать задачи **реального времени**, и почему «обычное планирование» часто не подходит? ⭐⭐⭐
- Как мультипрограммирование связано с тем, что процессы часто находятся в состоянии **ожидания I/O**? ⭐⭐

## Создание процессов: UNIX fork/exec и Windows CreateProcess

- Перечислите основные ситуации, когда в системе **создаются процессы** (boot, пользователь, родитель, batch) и объясните их отличия. ⭐
- Почему в UNIX исторически сложилась двухшаговая модель **fork() → exec()**, и какие преимущества она даёт? ⭐⭐
- Что именно копирует fork() и что **не копируется**? ⭐⭐
- Что такое **copy-on-write** и почему он делает fork эффективным в реальных ОС? ⭐⭐⭐
- В чём смысл «окна» между fork() и exec() для shell-подобных программ? Приведите примеры действий, которые выполняются именно там. ⭐⭐
- Что делает execve()/execvp() на уровне процесса, и почему говорят «заменяет образ процесса»? ⭐⭐
- Почему в Windows используют **CreateProcess** вместо fork/exec, и какие возможности он даёт сразу при запуске? ⭐⭐
- Какие типичные ошибки делают при работе с CreateProcess (например, командная строка, наследование дескрипторов, ожидание завершения)? ⭐⭐⭐
- Объясните, зачем родителю ждать дочерний процесс (waitpid / WaitForSingleObject), и что может случиться, если этого не делать. ⭐⭐
- Какие бывают причины завершения процесса и чем отличается «ошибка программы» от «принудительного убийства»? ⭐
- Чем отличается **exit-код** процесса от завершения **сигналом**, и почему ОС должна уметь различать эти сценарии? ⭐⭐
- Как родитель в UNIX может определить: ребёнок завершился нормально или был убит сигналом? ⭐⭐
- Что означает «завершение родителя ≠ завершение детей» и какие последствия это имеет для архитектуры сервисов? ⭐⭐
- Почему в многопользовательской системе нельзя разрешать «кому угодно» завершать чужие процессы? Какие механизмы авторизации обычно применяются? ⭐⭐⭐
- Почему fork в C++ может «ломать» привычный жизненный цикл объектов, и какие классы проблем это порождает? ⭐⭐
- Объясните разницу между `exit()` и `_exit()` в дочернем процессе после fork, и почему неправильный выбор может приводить к багам. ⭐⭐⭐
- Приведите примеры ресурсов (файлы, сокеты, lock-файлы, логи), которые после fork могут привести к ошибкам, и предложите стратегии безопасного дизайна. ⭐⭐⭐

## Идентификаторы и дескрипторы, управление процессами

- Что такое PID и какие свойства у него есть (уникальность, переиспользование, область видимости)? ⭐
- В чём отличие PID от HANDLE: почему PID — это «паспорт», а HANDLE — «ключ»? ⭐⭐
- Какие операции обычно можно выполнить, имея только PID, и какие требуют более «сильной ссылки» на объект? ⭐⭐
- Почему в Windows объект ядра может продолжать существовать после завершения процесса, и что определяет момент его уничтожения? ⭐⭐⭐
- Объясните, как в Linux соотносятся PID, TID и TGID, и почему главный поток имеет PID = TID. ⭐⭐
- Как формируется **дерево процессов** в UNIX, и почему процесс PID 1 играет особую роль? ⭐⭐
- Что такое процесс-группа и зачем она нужна в терминальной работе (например, Ctrl-C)? ⭐⭐
- Почему говорят, что Windows «не хранит дерево процессов так же жёстко», как UNIX, и какие практические последствия у этого есть? ⭐⭐
- Что такое «потеря иерархии» при передаче HANDLE другому процессу в Windows, и почему это меняет модель управления? ⭐⭐⭐
- Опишите модель состояний процесса: **Running / Ready / Blocked**. Что означает каждое состояние на практике? ⭐
- Разберите переходы между состояниями: какие из них вызваны **внешними событиями**, а какие — решениями **планировщика**? ⭐⭐
- Почему процесс может быть Ready, но не Running, и какие факторы влияют на то, когда он получит CPU? ⭐⭐
- На примере pipeline `cat | grep` объясните, почему один процесс может быть Blocked, а другой — Running/Ready, и как это связано с I/O. ⭐⭐
- Чем отличается блокировка на I/O от «просто ожидания кванта времени» с точки зрения эффективности системы? ⭐⭐⭐
- Что такое **PCB (Process Control Block)** и какие данные в нём критичны для переключения контекста? ⭐⭐
- Почему таблица процессов — это не просто список, а центральная структура для планировщика, сигналов, памяти и файлов? ⭐⭐⭐
- Опишите, что происходит при **переключении контекста**: какие части состояния сохраняются и где именно. ⭐⭐⭐
- Почему процесс может быть прерван тысячи раз, но «не замечать этого»? Какие условия должны соблюдаться для этой иллюзии? ⭐⭐
- Как связаны понятия **прерывание**, **обработчик**, **вектор прерываний** и последующее решение планировщика? ⭐⭐⭐
- Что такое `task_struct` в Linux и почему его считают «сердцем» модели процессов? ⭐⭐⭐

## Классическая модель потока

- Чем поток принципиально отличается от процесса с точки зрения модели ОС и программиста? ⭐
- Почему потоки называют «процессом внутри процесса» — что именно “внутри”, а что “общее”? ⭐⭐
- Какие типы задач выигрывают от потоков, а какие — почти не выигрывают? Приведите примеры. ⭐⭐
- Объясните идею перекрытия I/O и вычислений на примере: что означает «CPU не простаивает»? ⭐⭐
- Почему создание/уничтожение потоков обычно дешевле, чем процессов? За счёт каких ресурсов/операций? ⭐⭐
- В каких случаях многопоточность может ухудшить производительность по сравнению с однопоточной программой? ⭐⭐⭐
- Какие сущности относятся к «ресурсам процесса», а какие — к «контексту исполнения потока»? ⭐
- Почему процесс называют «единицей управления ресурсами», а поток — «единицей планирования»? ⭐⭐
- Какие ресурсы *обычно* общие для потоков одного процесса, а какие — строго индивидуальные? ⭐⭐
- Что именно хранится в «контексте потока», который требуется для переключения? ⭐⭐
- Как наличие общего адресного пространства упрощает взаимодействие потоков по сравнению с процессами? ⭐
- Почему отсутствие защиты между потоками делает ошибки опаснее, чем при IPC между процессами? ⭐⭐

## Параллелизм и планирование, ресурсы потока

- Чем псевдопараллелизм на одном CPU отличается от реального параллелизма на многоядерной системе? ⭐
- Как ОС решает, какой поток получит CPU следующим (в общих чертах)? ⭐⭐
- Что означают состояния running/ready/blocked/terminated для *потока*, и как они соотносятся с состояниями процессов? ⭐⭐
- Приведите пример перехода thread: running → blocked и объясните, почему это не «ошибка планировщика». ⭐⭐
- В каких ситуациях полезен добровольный yield, и почему он не гарантирует немедленного переключения? ⭐⭐
- Какие метрики/сигналы в системе вы бы смотрели, чтобы понять: приложение ограничено CPU или I/O? ⭐⭐⭐
- Почему у каждого потока должен быть собственный стек? Что сломается при «общем стеке»? ⭐⭐
- Что такое «кадры стека» и почему их структура важна для понимания выполнения потока? ⭐
- Какие данные разделяются потоками в куче/глобальной области, а какие — «живут» на стеке каждого потока? ⭐⭐
- Приведите пример ошибки, когда адрес локальной переменной передают в поток, и объясните причину. ⭐⭐
- Как различается типичная отладка багов «повреждение стека» vs «гонка данных» (на уровне симптомов)? ⭐⭐⭐
- Что означает «ядро не в курсе потоков» в user-level модели, и как библиотека переключает потоки? ⭐⭐
- Почему блокирующий системный вызов (например, read) блокирует **весь процесс** при user-level threads? ⭐⭐
- Почему page fault в user-level модели может «заморозить» все user threads, даже если они логически независимы? ⭐⭐⭐
- Какие обходные решения позволяют делать user-level потоки практичнее (select/poll/epoll, wrapper’ы), и чем они платят? ⭐⭐⭐
- В чём ключевые преимущества kernel threads над user-level threads, и какие накладные расходы они добавляют? ⭐⭐
- Объясните гибридную модель M:N: что планирует ОС, что планирует рантайм, и почему это похоже на goroutines/виртуальные потоки. ⭐⭐⭐

## Жизненный цикл потоков и базовые примитивы

- Опишите типичный жизненный цикл: create → работа → join. Какие ошибки бывают на каждом этапе? ⭐⭐
- Что произойдёт, если не вызвать join/detach для std::thread, и почему стандарт выбрал именно такое поведение? ⭐⭐
- Чем joinable поток отличается от detached (концептуально и по последствиям для ресурсов)? ⭐⭐
- Какие стратегии завершения потоков вы бы применили в сервере: «жёстко убить», «кооперативно остановить», «дождаться» — и почему? ⭐⭐⭐
- Почему важно проектировать «владение задачей» и «владение потоком» отдельно? ⭐⭐⭐
- Объясните назначение pthread_create: какие параметры критичны и почему start_routine имеет сигнатуру void* (void*)? ⭐⭐
- Почему нельзя передавать &i (адрес переменной цикла) как arg в pthread_create? Объясните, когда это «случайно работает». ⭐⭐
- Что делает pthread_join, и какие типичные ошибки приводят к EINVAL/EDEADLK/ESRCH? ⭐⭐⭐
- Зачем существуют pthread_attr_* и какие атрибуты вы бы реально настраивали в практике? ⭐⭐
- Что такое размер стека потока, чем опасен слишком маленький стек, и почему есть PTHREAD_STACK_MIN? ⭐⭐
- Когда вы бы использовали sched_yield, и почему он не является «средством синхронизации»? ⭐⭐
- Почему для программ с C/C++ runtime в Windows рекомендуют _beginthreadex, а не CreateThread? ⭐⭐
- Какие проблемы могут проявиться при CreateThread в программе, активно использующей CRT (printf/malloc/iostream), и почему? ⭐⭐⭐
- Зачем CloseHandle после завершения потока и почему его не делает _endthreadex? ⭐⭐
- Чем отличается HANDLE от thread id (TID) с точки зрения управления потоком? ⭐⭐
- Как бы вы организовали ожидание нескольких потоков в Windows и какие ограничения/нюансы у WaitForMultipleObjects? ⭐⭐⭐
- Сравните std::thread и std::jthread: какие риски снижает jthread и какой ценой? ⭐⭐
- Почему «RAII для потока» в виде std::jthread — важная идея для надёжности? ⭐⭐
- Объясните идею кооперативной отмены через std::stop_token: что должно делать тело потока? ⭐⭐
- Что произойдёт в примере с SortVector, если **не сохранять** возвращаемый std::jthread в переменную? Почему? ⭐⭐⭐

  ```cpp
  template <typename T>
  std::jthread SortVector(std::vector<T>& values) {
    return std::jthread{ [&values] {
      std::ranges::sort(values);
    } };
  }

  int main()
  {
    std::vector<int> numbers{ 10, 2, -5, 3, 17, 5 };
    std::vector<std::string> strings{ "one", "two", "three", "four", "five" };
    {
      auto t1 = SortVector(numbers); // Что если не сохранять результат в переменную?
      auto t2 = SortVector(strings);
    }
  }
  ```

- В каких случаях вы бы предпочли std::thread вместо std::jthread? ⭐⭐⭐

## Базовые понятия IPC и синхронизации

- Чем принципиально отличаются **синхронизация** и **коммуникация** между процессами/потоками?
   Приведите примеры, где нужна только одна из них, и где нужны обе. ⭐⭐
- Почему общая память «упрощает обмен данными», но одновременно «усложняет синхронизацию»? Разберите на примере инварианта структуры данных. ⭐⭐
- Дайте определения: **race condition**, **data race**, **atomicity violation**. Чем они отличаются и как проявляются? ⭐⭐⭐
- Что такое **критическая секция**? Какие свойства кода/ресурса делают участок «критическим»? ⭐
- Какие 4 условия корректного решения задачи критической секции (mutual exclusion) вы считаете ключевыми, и почему каждое из них важно на практике? ⭐⭐
- Почему пример с `counter++/counter--` на двух потоках может дать «случайный» результат, хотя на вид код симметричен? Опишите возможные межпоточные интерливинги. ⭐⭐

  ```cpp
  void Increment(int& counter) { ++counter; }
  void Decrement(int& counter) { --counter; }
  
  int main() {
    int counter = 0;
    std::jthread t1{ [&counter] {
    for (int i = 0; i < 1'000'000'000; ++i)
      Increment(counter);
    } };
    std::jthread t2{ [&counter] {
    for (int i = 0; i < 1'000'000'000; ++i)
      Decrement(counter);
    } };
    t1.join(); t2.join();
    std::cout << "Counter: " << counter << '\n';
  }
  ```

- Объясните, как исправить проблему в коде выше. ⭐⭐
- Что означает префикс `lock` в x86-инструкциях (например, `lock add`)? Как это связано с когерентностью кэша и «атомарностью»? ⭐⭐⭐
- Почему `volatile` **не является** механизмом синхронизации в C++? Приведите пример, где `volatile` не спасает от гонки. ⭐⭐⭐
- Объясните смысл **acquire/release** на примере «данные + флаг готовности». Что такое *happens-before*? ⭐⭐⭐

## Классические алгоритмы синхронизации

- Почему **busy waiting** считается проблемой в пользовательских программах? Назовите минимум 3 причины. ⭐
- Почему «запрет прерываний» работает как механизм взаимного исключения на одноядерной системе, и почему ломается на SMP? ⭐⭐
- Чем отличается «запрет прерываний» от «атомарной инструкции с блокировкой шины/кэша» с точки зрения охвата других CPU? ⭐⭐
- Почему инструкции `CLI/STI` недоступны в ring 3 и что произойдёт при попытке выполнить их в user mode? ⭐⭐
- В каких случаях ядро ОС всё же использует отключение прерываний, и почему время удержания должно быть «считанные инструкции»? ⭐⭐⭐
- Почему «простая lock-переменная» не обеспечивает взаимного исключения? Опишите гонку пошагово. ⭐
- Почему «прочитать lock дважды» не решает проблему? Сформулируйте, какая именно гарантия отсутствует. ⭐
- Что такое **Strict Alternation** и в чём его ключевой дефект с точки зрения требований к критической секции? ⭐⭐
- Приведите сценарий, где Strict Alternation блокирует процесс, хотя критическая секция свободна. Почему это плохо для производительности? ⭐⭐
- Можно ли «починить» Strict Alternation без аппаратной атомарности? Если да — какой ценой; если нет — почему? ⭐⭐⭐
- Объясните идею алгоритма Петерсона: зачем нужны **interested[]** и **turn** одновременно? ⭐⭐
- Докажите (словами) хотя бы одно свойство: mutual exclusion / progress / bounded waiting для алгоритма Петерсона. ⭐⭐⭐
- Почему реализация Петерсона на обычных `bool/int` может ломаться на современных CPU? ⭐⭐⭐
- Почему добавление `volatile` всё равно может не исправить Петерсона в C++? Что именно `volatile` гарантирует и чего не гарантирует? ⭐⭐⭐
- Как корректно реализовать Петерсона в C++ с `std::atomic`? Какие memory order’ы уместны и почему? ⭐⭐⭐

## Спинлоки

- Что делает TSL (test-and-set) и почему эта операция считается атомарной? ⭐⭐
- Сравните TSL и XCHG как примитивы: в чём концептуальная одинаковость и какие есть архитектурные нюансы. ⭐⭐
- Почему спинлоки эффективны только для «очень коротких» критических секций? Опишите критерии «короткости». ⭐⭐
- Что такое **starvation** в контексте спинлоков и почему отсутствие fairness — нормальная цена за простоту? ⭐⭐
- Какие техники применяют, чтобы уменьшить вред спина под конкуренцией (pause/yield/backoff)? Почему это помогает? ⭐⭐⭐
- Объясните, как `atomic_flag::test_and_set` реализует идею TSL. Что возвращает и почему это удобно для лока? ⭐⭐
- Почему в примере используются `memory_order_acquire` на lock и `memory_order_release` на unlock? Что будет, если поставить `relaxed`? ⭐⭐⭐
- Какие практические проблемы у такого спинлока: рекурсивность, fairness, влияние на энергопотребление, масштабирование на много ядер? ⭐⭐
- Почему внутри `std::atomic_flag` реализация может быть сложнее, чем кажется? Как это влияет на производительность? ⭐⭐⭐
- Как бы вы добавили в TSLLock `try_lock()` и «вежливое ожидание»? Какие компромиссы появятся? ⭐⭐

## Спинлоки в ядре: IRQ и вытеснение

- Зачем ядру нужно различать `spin_lock`, `spin_lock_irq` и `spin_lock_irqsave`? Опишите типичный сценарий для каждого. ⭐⭐⭐
- Почему «спать» внутри спинлока нельзя? Приведите пример deadlock-сценария. ⭐⭐
- В чём опасность, если обработчик прерывания попытается захватить тот же спинлок на том же CPU? Как это предотвращают? ⭐⭐⭐
- Почему `spin_lock_irq` может быть быстрее `irqsave`, но потенциально опаснее? ⭐⭐
- Что происходит с латентностью прерываний, если слишком часто/долго держать spin_lock_irqsave? Чем это грозит системе? ⭐⭐⭐
- В чём фундаментальная проблема примитивов `sleep()`/`wakeup()` как абстракции, если нет «памяти о сигнале»? ⭐⭐
- Разберите сценарий «потерянного wakeup» в producer-consumer из слайдов: какие именно шаги приводят к вечному сну? ⭐⭐⭐
- Почему «wakeup waiting bit» решает проблему только для двух процессов и начинает ломаться при увеличении числа участников? ⭐⭐⭐
- Как связаны sleep/wakeup, очереди ожидания и «ожидание по адресу» (sleep(address)/wakeup(address))? Почему привязка к адресу полезна? ⭐⭐
- Чем отличаются «sleep как задержка по времени» (nanosleep) и «sleep как IPC/синхронизация»? Почему путаница опасна? ⭐⭐
- Семафор как «счётчик сохранённых wakeup’ов»: объясните модель и почему она предотвращает потерю сигналов. ⭐⭐
- Почему операции `down/up` в семафоре должны быть атомарными? Что именно должно быть «неделимо» и какая гонка иначе появится? ⭐⭐⭐
- В задаче producer-consumer объясните роль трёх семафоров `mutex/empty/full` как **двух разных применений**: mutual exclusion vs ordering. ⭐⭐
- Сравните `std::counting_semaphore` и `std::condition_variable` как инструменты синхронизации: где проще семафор, а где — condvar? ⭐⭐⭐
- Как бы вы спроектировали ограничитель ресурсов (например, «не больше K одновременных запросов») в C++20: какие примитивы выберете и какие corner cases учтёте? ⭐⭐⭐

## Мьютексы: идея и реализация

- Почему мьютекс называют «упрощённым семафором»? В каких задачах семафор принципиально сильнее мьютекса? ⭐⭐
- Какие ошибки синхронизации мьютекс предотвращает, а какие **не предотвращает** (например, логические гонки и нарушение инвариантов)? ⭐⭐
- Объясните, почему «достаточно 1 бита», но на практике состояние мьютекса хранится как целое число/слово. ⭐⭐
- Разберите реализацию `mutex_lock` через TSL: что происходит при конкуренции, и почему используется `thread_yield()`? ⭐⭐
- Чем подход `mutex_lock + yield` отличается от чистого спинлока? Когда yield ухудшает ситуацию? ⭐⭐⭐
- Зачем нужен `trylock()`? Приведите пример алгоритма, где `trylock` позволяет избежать дедлока или улучшить latency. ⭐⭐
- Почему мьютексы «естественно» работают для потоков, но требуют дополнительных механизмов для процессов? ⭐⭐
- Какие способы межпроцессного мьютекса возможны: ядровые объекты, shared memory, файлы? Какие у каждого плюсы/минусы? ⭐⭐⭐
- Какие свойства должен иметь мьютекс, чтобы быть безопасным для межпроцессной синхронизации? ⭐⭐⭐
- Почему «мьютекс в user space» обычно быстрее, чем ядровая блокировка, и в каких случаях это перестаёт быть правдой? ⭐⭐⭐

## Futex и condition variables

- Какую проблему выбора «spinlock vs блокировка через ядро» решает futex? ⭐⭐
- Объясните, что означает «в отсутствии конкуренции ядро не вовлекается вообще». За счёт чего это достигается? ⭐⭐⭐
- Опишите жизненный цикл захвата futex: атомарная попытка → системный вызов → очередь ожидания → пробуждение. ⭐⭐⭐
- Почему futex редко используется напрямую прикладным программистом, но часто встречается «под капотом»? ⭐⭐
- Какие ошибки могут возникнуть при неправильном использовании futex (например, потерянные пробуждения, ABA-сценарии, неверные ожидания)? ⭐⭐⭐
- Какие гарантии даёт `pthread_mutex_lock` и что он НЕ гарантирует (например, порядок пробуждений/справедливость)? ⭐⭐
- Почему условные переменные всегда используются **вместе с мьютексом**? ⭐⭐
- Что означает фраза «условные переменные не накапливают сигналы» и чем это отличается от семафоров? ⭐⭐⭐
- Объясните, почему `pthread_cond_wait(&cond, &mutex)` атомарно «отпускает мьютекс и засыпает». Почему это важно? ⭐⭐⭐
- В producer/consumer примере почему проверка условия должна быть в `while`, а не `if`? Назовите минимум две причины. ⭐⭐
- Чем отличаются `std::lock_guard` и `std::unique_lock`? Почему `wait()` требует именно `unique_lock`? ⭐⭐
- Что такое spurious wakeup и почему он возможен даже при корректной логике notify? ⭐⭐⭐
- В чём разница между `cv.wait(lock)` и `cv.wait(lock, predicate)` с точки зрения безопасности и читаемости? ⭐⭐
- Какую типичную ошибку делают при использовании `notify_one()`/`notify_all()` (например, уведомление без изменения состояния)? ⭐⭐
- Опишите корректный дизайн очереди producer-consumer на C++: где хранится условие, где мьютекс, где уведомление, что защищаем. ⭐⭐⭐

## std::mutex и разновидности мьютексов

- В каких случаях оправдан `std::recursive_mutex`, и почему его часто считают «запахом дизайна»? ⭐⭐⭐
- Чем полезны `std::timed_mutex` и таймауты в синхронизации? Приведите пример, где таймаут — часть корректности. ⭐⭐⭐
- Почему RAII-обёртки (lock_guard/unique_lock) уменьшают вероятность дедлоков и утечек блокировки? ⭐⭐
- Какие риски возникают, если внутри критической секции делать I/O или ждать другие ресурсы? ⭐⭐
- Какие способы избежать дедлоков при захвате нескольких мьютексов (lock ordering, std::lock, try_lock loop)? ⭐⭐⭐
- Чем `std::shared_mutex` принципиально отличается от обычного `std::mutex` по модели допуска потоков? ⭐⭐
- В каких сценариях `std::shared_mutex` реально ускоряет систему, а в каких может замедлить? ⭐⭐
- Почему стандарт не гарантирует справедливость в `std::shared_mutex` и к чему это приводит для писателей? ⭐⭐⭐
- Почему upgrade (shared → unique) небезопасен без выхода? Опишите гонку, которая возникает при «наивном апгрейде». ⭐⭐⭐
- Почему `shared_mutex` подходит только для коротких критических секций, несмотря на «параллельность чтения»? ⭐⭐

## FairRWLock и мониторы

- В чём идея writer-preferred RWLock и как она предотвращает starvation писателей? ⭐⭐
- Какие поля нужны FairRWLock (active readers / waiting writers / active writer) и какие инварианты они должны соблюдать? ⭐⭐⭐
- Почему в `lock_shared()` читатели должны ждать не только `active_writer == false`, но и `waiting_writers == 0`? ⭐⭐⭐
- Объясните логику пробуждений: почему в `unlock()` иногда будим писателя, а иногда всех читателей? ⭐⭐⭐
- Какие типичные ошибки приводят к дедлоку или «зависанию» в RWLock (например, неверный notify, неправильные условия ожидания)? ⭐⭐⭐
- Почему мониторы появились как реакция на «опасность семафоров»? Какие классы ошибок они уменьшают? ⭐⭐
- Что означает «только один поток активен в мониторе» и как это реализуется на практике (на уровне языка/рантайма)? ⭐⭐
- Сравните семантику сигнализации Хоара и Бринч Хансена: кто продолжает выполнение после `signal()` и почему это важно. ⭐⭐⭐
- Почему даже в мониторах сигналы condition variables «не копятся»? Какие последствия это имеет для дизайна? ⭐⭐⭐
- Как модель монитора в Java (`synchronized`, `wait/notify`) отличается от «классического» монитора с отдельными condition variables? ⭐⭐⭐
- Какие проблемы появляются при IPC через сообщения в распределённой среде: потери, дубликаты, порядок, подмена отправителя? ⭐⭐
- Зачем нужны ACK + ретрансляции и почему это сразу приводит к необходимости sequence numbers? ⭐⭐⭐
- Чем отличается адресация «процесс → процесс» от mailboxes? Как mailboxes помогают масштабировать систему? ⭐⭐
- Сравните rendezvous (без буфера) и буферизированный обмен: какие плюсы/минусы по latency, throughput и сложности? ⭐⭐⭐
- Объясните producer–consumer без общей памяти через «пустые/полные» сообщения: какой инвариант делает систему корректной? ⭐⭐⭐

## Барьеры синхронизации (phase synchronization), ошибки работы с многопоточностью

- Объясните, чем барьер отличается от мьютекса/семафора: какую задачу он решает и какую — нет? ⭐⭐
- В каких типах алгоритмов барьер является «естественным» примитивом, и почему там нельзя просто поставить мьютекс? ⭐⭐
- Что означает «никто не переходит к фазе n+1, пока все не закончили фазу n» в терминах корректности данных между итерациями? ⭐⭐
- Как устроен переиспользуемый барьер: зачем нужны счётчик участников и «поколение»? ⭐⭐⭐
- Объясните, какую роль играет `completion step` в `std::barrier`, и приведите пример, где без него легко ошибиться. ⭐⭐⭐
- Какие ошибки приводят к дедлоку на барьере, и какие стратегии защиты применяют промышленные реализации? ⭐⭐⭐
- Что такое «straggler» и почему он может полностью «убить» производительность параллельного цикла, даже если барьер реализован идеально? ⭐⭐
- Объясните паттерн «current/next + swap на барьере»: какие гонки он предотвращает и почему это лучше, чем писать в один и тот же массив. ⭐⭐⭐

  ```cpp
  std::barrier sync(N, [&]{
    std::swap(current, next);
  });

  void worker(chunk c) {
    for (int it=0; it<steps; ++it) {
      compute(next, current, c);  // читаем из current, пишем в next
      sync.arrive_and_wait();
    }
  }
  
  ```

- В каких ситуациях двойная буферизация не спасает и что тогда делают? ⭐⭐⭐
- Какие инварианты должны выполняться на границе итерации, чтобы следующий шаг не увидел «смешанные» данные? ⭐⭐
- Почему нельзя путать синхронизационный барьер (group barrier) и memory fence? Приведите пример, где один нужен, а другой — нет. ⭐⭐⭐
- Опишите сценарий, когда из-за out-of-order execution «флаг готовности» становится видимым раньше данных, и к чему это приводит. ⭐⭐
- Объясните, как пара `store(..., release)` и `load(..., acquire)` обеспечивает корректную публикацию данных (happens-before). ⭐⭐⭐
- В примере с `turn` и `x`: почему `x` можно читать `relaxed`, но всё равно гарантированно увидеть 100 после `acquire` на `turn`? ⭐⭐⭐
  
  ```cpp
  std::atomic<int> turn{0};
  std::atomic<int> x{0};
  
  // writer:
  x.store(100, std::memory_order_relaxed);
  turn.store(1, std::memory_order_release); // публикуем флаг ПОСЛЕ данных

  // reader:
  while (turn.load(std::memory_order_acquire) != 1) { /* spin */ }
  int v = x.load(std::memory_order_relaxed); // видим 100 гарантированно  
  ```

- В каких случаях уместно использовать `std::atomic_thread_fence`, а когда лучше выразить зависимость через acquire/release на конкретных атомиках? ⭐⭐⭐
- Разберите по шагам механизм инверсии приоритетов с потоками L/M/H: почему наличие «среднего» приоритета делает ситуацию хуже? ⭐⭐⭐
- Сравните Priority Inheritance и Priority Ceiling: что они гарантируют, какие вводят накладные расходы и какие риски/сложности (например, цепочки наследования или настройка потолков)? ⭐⭐⭐
- Почему «отключить прерывания» — плохое решение для пользовательского кода и непереносимая стратегия для общей синхронизации? ⭐⭐

## Планирование процессов, контекст планирования

- Объясните, почему в многопрограммной системе вообще возникает необходимость планирования CPU, и чем «ready state» отличается от «running» и «blocked». ⭐
- В чём разница между планировщиком и алгоритмом планирования? Приведите примеры решений, которые принимает планировщик. ⭐
- Почему принципы планирования применимы не только к процессам, но и к потокам? Что меняется, когда планируем потоки вместо процессов? ⭐⭐
- Сравните роль планирования в пакетных системах, на персональных компьютерах и на серверах. Почему важность планирования так различается? ⭐⭐
- Приведите примеры сценариев, где планирование становится критичным даже на «быстром» компьютере (рендеринг, игры и т. п.). Что именно в нагрузке делает планирование важным? ⭐⭐
- Почему в IoT/смартфонах планирование тесно связано с энергопотреблением? Какие компромиссы при этом возникают? ⭐⭐
- Опишите, что происходит при context switch на уровне CPU и ОС (режим ядра, регистры, память, кэши). Почему это «дорого»? ⭐⭐
- Какие компоненты накладных расходов переключения контекста зависят от архитектуры памяти (MMU, TLB) и кэширования? ⭐⭐
- Почему слишком частые переключения процессов могут снижать реальную полезную производительность системы даже при высокой загрузке CPU? ⭐⭐
- Как выбор длины кванта (time slice) влияет на долю времени, теряемую на переключения? Объясните на качественном уровне. ⭐⭐
- Какие метрики или симптомы в системе могут указывать, что накладные расходы на переключения стали чрезмерными? ⭐⭐⭐

## Виды процессов и их планирование

- Дайте определение CPU burst и I/O burst. Почему ключевым фактором для классификации CPU-bound/I/O-bound считается длина CPU burst? ⭐
- Приведите примеры типичных CPU-bound и I/O-bound задач в современных ОС и объясните их поведение через bursts. ⭐⭐
- Почему ускорение CPU в исторической перспективе «делает процессы более I/O-bound»? Какие технологические причины лежат в основе? ⭐⭐
- Объясните, почему для производительности системы важно «смешивать» CPU-bound и I/O-bound процессы (баланс CPU и устройств). ⭐⭐
- Что будет происходить с загрузкой CPU и диска, если в памяти окажутся только CPU-bound задачи, а затем только I/O-bound? Почему это плохо? ⭐⭐
- Как выбор алгоритма планирования может улучшать «параллелизм» CPU и I/O в системе? Приведите пример стратегии для I/O-bound процессов. ⭐⭐⭐
- Перечислите основные события, в которых ОС может принять решение о перепланировании (создание, завершение, блокировка, I/O interrupt, таймер). Почему этих событий достаточно? ⭐⭐
- В чём принципиальная разница между preemptive и nonpreemptive планированием? Какие риски есть у каждого подхода? ⭐⭐
- Почему наличие периодических прерываний таймера критично для вытесняющего планирования? Что произойдёт, если таймера нет? ⭐⭐
- Объясните, почему вытесняющая многозадачность важна не только для приложений, но и для ядра (preemptive kernel). ⭐⭐
- Приведите пример ситуации, когда невытесняющее планирование может выглядеть привлекательным, и объясните, чем это может обернуться в реальной системе. ⭐⭐⭐

## Категории систем и цели планирования

- Сравните ключевые цели планирования для batch, interactive и real-time систем. Почему одна и та же метрика не подходит всем? ⭐⭐
- Что такое fairness в планировании? Как «справедливость» может конфликтовать с производительностью или политикой приоритетов? ⭐⭐⭐
- Объясните разницу между throughput и turnaround time. Почему максимизация throughput может ухудшать turnaround? ⭐⭐
- Почему CPU utilization — спорная метрика качества планирования в batch-системах? Когда она всё же полезна? ⭐⭐
- Что такое response time в интерактивных системах и почему «пропорциональность ожиданиям пользователя» важна как отдельная цель? ⭐⭐
- Почему в real-time системах «правильный ответ слишком поздно» может быть эквивалентен ошибке? Приведите примеры. ⭐⭐
- Чем отличается predictability от просто «высокой скорости» в real-time/мультимедиа? Почему jitter критичен? ⭐⭐⭐
- Опишите алгоритм FCFS и объясните, почему его называют «справедливым», но при этом он может давать плохую среднюю производительность. ⭐⭐
- Что такое «эффект конвоя» в FCFS? Опишите сценарий с CPU-bound и множеством I/O-bound процессов и последствия для времени завершения. ⭐⭐⭐
- Объясните идею SJF (Shortest Job First) и почему он минимизирует среднее turnaround time при известной длительности задач. ⭐⭐
- В каких условиях SJF является оптимальным, а в каких — нет? Приведите контрпример с разными временами прихода задач. ⭐⭐⭐
- Чем SRTN (Shortest Remaining Time Next) отличается от SJF и почему вытеснение помогает «коротким» задачам? ⭐⭐
- Какие практические проблемы возникают при попытке применить SJF/SRTN в реальных ОС (оценка времени, ошибки прогнозов, starvation)? ⭐⭐⭐

## Интерактивные системы: Round Robin и приоритеты

- Опишите работу Round Robin и объясните роль кванта времени. Почему RR считают «простым и справедливым»? ⭐⭐
- Как слишком короткий квант влияет на CPU efficiency, а слишком длинный — на response time? Почему диапазон 20–50 мс часто компромиссный? ⭐⭐
- В каких ситуациях RR фактически становится почти невытесняющим? Свяжите это со средним CPU burst. ⭐⭐⭐
- Что такое планирование по приоритетам? Какие реальные причины заставляют ОС вводить приоритеты? ⭐⭐
- Почему приоритетные схемы могут приводить к starvation? Какие механизмы борьбы с этим используются (aging, динамика приоритета и т. п.)? ⭐⭐⭐
- Объясните идею динамического повышения приоритета для I/O-bound процессов. Почему это улучшает общую производительность системы? ⭐⭐⭐
- Почему удобно сочетать приоритеты «между классами» и round robin «внутри класса»? Какие плюсы и минусы у такого гибрида? ⭐⭐
- Опишите идею multiple queues (многоуровневых очередей) и объясните, как они помогают одновременно интерактивным и вычислительным задачам. ⭐⭐
- Почему увеличение кванта на нижних уровнях (1, 2, 4, 8, …) уменьшает число дорогих переключений/свапов в некоторых системах? ⭐⭐⭐
- Приведите пример «обхода» политики многоуровневых очередей пользователем (например, искусственно имитировать интерактивность). Почему «правильно в теории» сложно реализовать на практике? ⭐⭐⭐
- Как можно адаптировать идею SJF к интерактивным системам, если длительности заранее неизвестны? Опишите подход с прогнозированием. ⭐⭐
- Объясните формулу экспоненциального сглаживания (aging) для оценки следующего CPU burst и смысл параметра (a). ⭐⭐⭐
- В чём идея guaranteed scheduling (примерно 1/n CPU каждому) и как измерение «получено vs положено» влияет на выбор следующего процесса? ⭐⭐
- Объясните основную идею Linux CFS на концептуальном уровне: что такое «spent execution time», зачем дерево, почему выбирают «самого недополучившего». ⭐⭐⭐
- Сравните lottery scheduling и fair-share scheduling: что именно считается «справедливостью» в каждом, и в каких сценариях один подход предпочтительнее другого? ⭐⭐⭐

## Планирование в системах реального времени

- Что делает систему «реального времени» отличной от просто «быстрой» системы? Почему «правильный ответ слишком поздно» может считаться ошибкой? ⭐⭐
- Приведите по 2–3 примера hard real-time и soft real-time систем и объясните, что именно является дедлайном в каждом примере. ⭐⭐
- В чём ключевое различие между hard real-time и soft real-time с точки зрения последствий пропуска дедлайна? ⭐⭐
- Почему для мультимедиа-систем важна не только скорость, но и предсказуемость (jitter)? Как планировщик может влиять на качество аудио/видео? ⭐⭐⭐
- Объясните, почему в некоторых real-time системах вытеснение «иногда не требуется». При каких предпосылках это возможно? ⭐⭐⭐
- Сравните периодические и непериодические события в real-time системах. Чем они отличаются с точки зрения планирования и гарантий? ⭐⭐
- Раскройте смысл условия планируемости ($\sum (C_i/P_i) \le 1$). Что означают ($C_i$) и ($P_i$) физически и как интерпретировать сумму? ⭐⭐
- Почему при ($\sum (C_i/P_i) > 1$) система принципиально не может быть корректно запланирована? Какие стратегии остаются в таком случае? ⭐⭐⭐
- В приведённом примере (Периоды: 100/200/500 мс и время обработки 50/30/100 мс) объясните, почему система считается планируемой? ⭐⭐
- В каких реальных ситуациях допущение «накладные расходы на переключение контекста можно игнорировать» становится неверным и как это влияет на проверку планируемости? ⭐⭐⭐
- Предложите метод, как учитывать накладные расходы (context switch, обработка прерываний) при оценке планируемости, не углубляясь в конкретный алгоритм. ⭐⭐⭐
- Почему добавление непериодических задач усложняет гарантии дедлайнов даже при выполнении условия для периодических задач? ⭐⭐⭐
- В чём разница между static scheduling и dynamic scheduling в real-time системах? Какие сведения нужны «заранее» в статическом варианте? ⭐⭐
- Приведите пример системы/сценария, где статическое планирование предпочтительнее, и объясните, почему. ⭐⭐
- Приведите пример системы/сценария, где динамическое планирование неизбежно, и объясните, какую неопределённость оно покрывает. ⭐⭐
- Какие риски и ограничения появляются при статическом планировании, если «идеальная информация заранее» недоступна или ошибочна? ⭐⭐⭐
- Как бы вы объяснили компромисс «предсказуемость vs гибкость» между static и dynamic scheduling на уровне архитектуры системы? ⭐⭐⭐

## Политика против механизма, user-level потоки

- Дайте определения «механизм» и «политика» применительно к планированию. Почему их разделение считается фундаментальным принципом ОС? ⭐⭐
- На примере СУБД объясните, почему приложение может «лучше знать», как планировать свои дочерние задачи/потоки, чем ядро ОС. ⭐⭐
- Приведите примеры параметров/интерфейсов ОС, через которые пользовательский процесс может влиять на политику, не реализуя механизм (приоритеты, квоты и т. п.). ⭐⭐
- Какие опасности возникают, если приложениям дать слишком много контроля над политикой (например, возможность бесконтрольно повышать приоритет)? Как ОС может это ограничивать? ⭐⭐⭐
- Опишите ситуацию, где отсутствие разделения policy/mechanism приводит к заметной потере производительности или нарушению требований по времени. ⭐⭐⭐
- Почему наличие двух уровней параллелизма (процессы и потоки) усложняет планирование по сравнению с «только процессами»? ⭐⭐
- Объясните, как происходит планирование при user-level threads: кто и что планирует, и почему отсутствует принудительное вытеснение потоков таймером? ⭐⭐
- В чём главный практический недостаток user-level threads при блокирующих операциях ввода-вывода? Как он проявляется для пользователя? ⭐⭐
- Объясните, как планирование отличается для kernel-level threads и почему становится возможна «перемежающаяся» последовательность потоков разных процессов. ⭐⭐
- Почему переключение между kernel-level threads обычно дороже, чем между user-level threads? Какие компоненты ОС делают его дорогим? ⭐⭐⭐
- Почему ядру выгоднее (при прочих равных) продолжать выполнять поток в том же процессе, а не переключаться на поток другого процесса? Свяжите ответ с памятью и кэшами. ⭐⭐⭐
- В чём идея гибридного подхода (сочетание user-level и kernel-level) и какие проблемы каждого уровня он пытается компенсировать? ⭐⭐⭐
- Сформулируйте общий вывод лекции для случая real-time + threads: какие свойства планировщика становятся ключевыми (дедлайны, предсказуемость, накладные расходы, политика/механизм) и почему? ⭐⭐⭐

