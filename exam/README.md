# Вопросы к экзамену

- [Вопросы к экзамену](#вопросы-к-экзамену)
  - [Общие сведения об ОС](#общие-сведения-об-ос)
  - [Процессы/переключение контекста и регистры, режимы процессора](#процессыпереключение-контекста-и-регистры-режимы-процессора)
  - [Память, виртуальная память и MMU, шины](#память-виртуальная-память-и-mmu-шины)
  - [Базовые абстракции ОС: процессы, адресные пространства, файлы](#базовые-абстракции-ос-процессы-адресные-пространства-файлы)
  - [Пользователи, UID/GID и модель прав](#пользователи-uidgid-и-модель-прав)
  - [Адресное пространство и аппаратная защита](#адресное-пространство-и-аппаратная-защита)
  - [Файловые системы: пути, каталоги, операции](#файловые-системы-пути-каталоги-операции)
  - [Базовые понятия: процесс, программа, абстракция ОС, параллелизм](#базовые-понятия-процесс-программа-абстракция-ос-параллелизм)
  - [Создание процессов: UNIX fork/exec и Windows CreateProcess](#создание-процессов-unix-forkexec-и-windows-createprocess)
  - [Идентификаторы и дескрипторы, управление процессами](#идентификаторы-и-дескрипторы-управление-процессами)
  - [Классическая модель потока](#классическая-модель-потока)
  - [Параллелизм и планирование, ресурсы потока](#параллелизм-и-планирование-ресурсы-потока)
  - [Жизненный цикл потоков и базовые примитивы](#жизненный-цикл-потоков-и-базовые-примитивы)
  - [Базовые понятия IPC и синхронизации](#базовые-понятия-ipc-и-синхронизации)
  - [Классические алгоритмы синхронизации](#классические-алгоритмы-синхронизации)
  - [Спинлоки](#спинлоки)
  - [Спинлоки в ядре: IRQ и вытеснение](#спинлоки-в-ядре-irq-и-вытеснение)
  - [Мьютексы: идея и реализация](#мьютексы-идея-и-реализация)
  - [Futex и condition variables](#futex-и-condition-variables)
  - [std::mutex и разновидности мьютексов](#stdmutex-и-разновидности-мьютексов)
  - [FairRWLock и мониторы](#fairrwlock-и-мониторы)
  - [Барьеры синхронизации (phase synchronization), ошибки работы с многопоточностью](#барьеры-синхронизации-phase-synchronization-ошибки-работы-с-многопоточностью)
  - [Планирование процессов, контекст планирования](#планирование-процессов-контекст-планирования)
  - [Виды процессов и их планирование](#виды-процессов-и-их-планирование)
  - [Категории систем и цели планирования](#категории-систем-и-цели-планирования)
  - [Интерактивные системы: Round Robin и приоритеты](#интерактивные-системы-round-robin-и-приоритеты)
  - [Планирование в системах реального времени](#планирование-в-системах-реального-времени)
  - [Политика против механизма, user-level потоки](#политика-против-механизма-user-level-потоки)
  - [Память как ресурс](#память-как-ресурс)
  - [Память в ранних системах](#память-в-ранних-системах)
  - [Адресные пространства](#адресные-пространства)
  - [Защита и релокация, swapping](#защита-и-релокация-swapping)
  - [Управление памятью с помощью битовых карт](#управление-памятью-с-помощью-битовых-карт)
  - [Управление памятью на основе списков сегментов](#управление-памятью-на-основе-списков-сегментов)
  - [Алгоритмы выбора «дыры» (First/Next/Best/Worst Fit)](#алгоритмы-выбора-дыры-firstnextbestworst-fit)
  - [Виртуальная память](#виртуальная-память)
  - [Устройство вирутальной памяти](#устройство-вирутальной-памяти)
  - [Переход от физических адресов к виртуальным](#переход-от-физических-адресов-к-виртуальным)
  - [Что происходит аппаратно при включении paging: pipeline flush и очистка TLB](#что-происходит-аппаратно-при-включении-paging-pipeline-flush-и-очистка-tlb)
  - [Виртуальная память в многоядерных системах](#виртуальная-память-в-многоядерных-системах)
  - [Переключение адресных пространств, кеши и безопасность](#переключение-адресных-пространств-кеши-и-безопасность)
  - [TLB и переключение контекста: flush, ASID/PCID, многоуровневые TLB](#tlb-и-переключение-контекста-flush-asidpcid-многоуровневые-tlb)
  - [Инвертированные таблицы страниц (IPT) и Radix Page Tables: эволюция масштабируемости](#инвертированные-таблицы-страниц-ipt-и-radix-page-tables-эволюция-масштабируемости)
  - [Основы замещения страниц и цели политики](#основы-замещения-страниц-и-цели-политики)
  - [Алгоритмы Optimal Page Replacement и NRU](#алгоритмы-optimal-page-replacement-и-nru)
  - [Алгоритмы FIFO и Second Chance](#алгоритмы-fifo-и-second-chance)
  - [Алгоритмы Clock и Enhanced Clock](#алгоритмы-clock-и-enhanced-clock)
  - [Алгоритмы LRU и NFU](#алгоритмы-lru-и-nfu)
  - [Алгоритмы Aging и Working Set](#алгоритмы-aging-и-working-set)
  - [Алгоритмы WSClock и гибридные алгоритмы](#алгоритмы-wsclock-и-гибридные-алгоритмы)


## Общие сведения об ОС

- Дайте определение операционной системы и объясните, какие задачи она решает в современном компьютере. ⭐
- Почему прикладные программы обычно не работают напрямую с «железом»? Какие проблемы возникли бы без ОС? ⭐⭐
- Объясните, как ОС управляет ресурсами при многопользовательской работе. Какие типы конфликтов она предотвращает? ⭐⭐
- Что такое мультиплексирование во времени и в пространстве? Приведите по 2 примера каждого. ⭐⭐
- В каких типах устройств ОС может быть не нужна? Приведите примеры и объясните почему. ⭐⭐
- Чем RTOS отличается от «полноценной» ОС общего назначения? В каких областях RTOS критична? ⭐⭐
- Опишите базовую архитектуру ПК (CPU–память–I/O) и роль системной шины в этой модели. ⭐
- Что означает, что ОС «создаёт абстракции»? Приведите пример перехода от «блоков диска» к «файлам». ⭐⭐
- Что такое драйвер устройства и почему драйверы часто выполняются в режиме ядра? ⭐⭐
- Назовите и сравните три способа установки драйверов (пересборка ядра, загрузка при старте, hotplug). ⭐⭐
- Что такое прерывание (interrupt) и зачем оно нужно при вводе-выводе? Опишите путь от устройства до обработчика. ⭐⭐⭐
- Сравните методы I/O: busy waiting, interrupts, DMA — плюсы/минусы и типичные сценарии использования. ⭐⭐⭐
- Опишите процесс загрузки компьютера: что делает BIOS/UEFI, как выбирается загрузчик и что происходит при запуске ядра ОС. ⭐⭐⭐
- Сравните BIOS и UEFI (MBR vs GPT/ESP, ограничения, возможности). Почему UEFI считают «маленькой ОС»? ⭐⭐⭐

## Процессы/переключение контекста и регистры, режимы процессора

- Что такое context switch и почему при нём важно сохранять/восстанавливать состояние процессора? ⭐⭐
- Какие регистры процессора важны для ОС (PC, SP, PSW) и как ОС использует/учитывает их? ⭐⭐
- Чем архитектура процессора отличается от микроархитектуры? Почему ОС в основном «видит» архитектуру? ⭐⭐
- Объясните, что такое конвейер (pipeline) и как он повышает производительность. Какие сложности он создаёт? ⭐⭐⭐
- Что такое суперскалярный процессор и «внеочередное выполнение»? Почему это может быть важно для ОС? ⭐⭐⭐
- Сравните kernel mode и user mode: какие инструкции/возможности доступны в каждом режиме и почему? ⭐⭐
- Что такое системный вызов (syscall) и чем он отличается от обычного вызова функции? Опишите общий механизм «trap в ядро». ⭐⭐⭐
- Какие бывают аппаратные traps (кроме syscall)? Как ОС может реагировать на исключительные ситуации? ⭐⭐

## Память, виртуальная память и MMU, шины

- Как ОС управляет памятью при одновременной работе нескольких программ? Какие цели преследуются (справедливость/защита/безопасность)? ⭐⭐
- Что такое виртуальная память и зачем она нужна? Опишите идею «RAM как кэш для диска/SSD». ⭐⭐
- Какова роль MMU? Что означает «преобразование виртуальных адресов в физические»? ⭐⭐⭐
- Что такое кэш CPU (L1/L2/L3)? Объясните термины cache hit и cache miss и влияние на производительность. ⭐⭐
- Приведите примеры кэширования в ОС (не в железе) и объясните, почему это ускоряет систему. ⭐⭐
- Сравните HDD и SSD: как устроены, почему HDD медленнее при случайном доступе, и что усложняет запись в SSD. ⭐⭐
- Что такое «шина» в архитектуре компьютера? Почему современные системы используют несколько шин вместо одной? ⭐⭐
- Чем PCIe принципиально отличается от старых параллельных общих шин (PCI/ISA)? Как масштабирование по линиям влияет на скорость? ⭐⭐⭐

## Базовые абстракции ОС: процессы, адресные пространства, файлы

- Почему в ОС вообще нужны абстракции (процессы/адресные пространства/файлы), и какие проблемы «железа» они скрывают от программиста? ⭐⭐
- Чем «программа» отличается от «процесса», и какие атрибуты превращают код на диске в выполняющийся процесс? ⭐
- Как адресное пространство помогает одновременно в удобстве программирования и в безопасности? ⭐⭐
- Приведите пример: какая одна и та же операция может выглядеть «как работа с файлом», но на самом деле быть работой с устройством или IPC? Объясните идею унификации. ⭐⭐
- Какие последствия для дизайна ОС возникают из того, что процесс и файл — ключевые универсальные абстракции почти во всех ОС? ⭐⭐⭐
- Что именно хранит ОС о процессе в «таблице процессов», и зачем там нужны значения регистров и позиции в файлах? ⭐⭐
- Какие ресурсы (кроме памяти) обычно «прикреплены» к процессу, и что должно случиться с ними при завершении процесса? ⭐⭐
- Опишите, что должно произойти при приостановке и последующем возобновлении процесса, чтобы программа «ничего не заметила». ⭐⭐
- Как вы объясните различие между состоянием «спит», «выполняется», «остановлен», «зомби» с точки зрения ОС и родителя процесса? ⭐⭐
- Почему процессы часто называют «контейнерами выполнения», и в каком смысле это похоже/не похоже на контейнеры уровня Docker? ⭐⭐⭐
- Какие выводы о системе можно сделать по списку процессов `ps aux`: что искать в USER/PID/STAT/COMMAND? ⭐
- Чем отличаются VSZ/VIRT и RSS/RES, и почему «много VIRT» не всегда означает «проблема с памятью»? ⭐⭐
- Как интерпретировать %CPU в `top` на многоядерной машине: когда 100% — это «всё» и когда — «одно ядро»? ⭐⭐
- Что означает load average, и почему он может быть высоким даже при низком %CPU? ⭐⭐⭐
- Как бы вы нашли «подозрительный» процесс, который редко использует CPU, но постоянно держит диск занятым? Какие поля/инструменты помогут? ⭐⭐⭐
- Почему в UNIX-подобных системах естественно возникает дерево процессов? Что даёт модель «родитель–ребёнок»? ⭐⭐
- Сравните: IPC через каналы (pipes), через файлы и через сокеты — в чём различие по модели использования и по стоимости? ⭐⭐⭐
- Что такое сигнал: чем он принципиально отличается от «сообщения» IPC, и почему его сравнивают с прерываниями? ⭐⭐
- Придумайте сценарий, где сигнал — хороший механизм (например, таймер/ошибка), и сценарий, где сигнал — плохой выбор и лучше IPC. ⭐⭐⭐
- Что может пойти не так, если процесс «не готов» принимать сигнал (нет обработчика) — почему это иногда полезно, а иногда опасно? ⭐⭐

## Пользователи, UID/GID и модель прав

- Зачем ОС связывает процесс с UID/GID, и как это влияет на доступ к файлам и процессам других пользователей? ⭐⭐
- Чем отличается «пользователь» от «группы» в практическом управлении доступом? Приведите пример политики доступа. ⭐⭐
- Почему root (администратор) — одновременно полезная и опасная концепция? Какие риски она создаёт? ⭐⭐
- Какую информацию можно извлечь из `/etc/passwd`, и почему наличие записи там ещё не означает возможность интерактивного входа? ⭐⭐⭐
- Опишите типичную модель «минимально необходимых прав» и как она реализуется на практике в UNIX через пользователей/группы/права. ⭐⭐⭐
- В чём принципиальная разница между `su` и `sudo` с точки зрения модели безопасности? ⭐⭐
- Почему `su` считается менее безопасным подходом в командах/организациях, и как это связано с паролями и аудитом? ⭐⭐
- Что именно меняется при `su`: какие части «сессии» (окружение, текущий каталог, права) могут вести себя иначе? ⭐⭐⭐
- Зачем `sudo` обычно просит пароль текущего пользователя, а не root? Как это помогает контролю и расследованиям? ⭐⭐
- Опишите сценарий, когда `sudo` может быть опасен при неверной настройке (например, чрезмерные права), и как это предотвратить. ⭐⭐⭐

## Адресное пространство и аппаратная защита

- Что такое адресное пространство процесса, и почему «несколько процессов в памяти» требуют аппаратной поддержки? ⭐⭐
- Как процессор и ОС вместе обеспечивают, что процесс не может читать/писать память другого процесса? (Опишите на уровне идеи.) ⭐⭐⭐
- Что такое режим пользователя и режим ядра, и почему системные вызовы требуют перехода между ними? ⭐⭐
- Почему ранние системы могли обходиться без защиты памяти, и какие компромиссы это накладывало на надёжность? ⭐⭐
- Почему во встраиваемых системах защита памяти иногда отсутствует и сегодня: когда это оправдано, а когда — нет? ⭐⭐⭐
- Объясните идею виртуальной памяти: какие иллюзии она создаёт для процесса и какие задачи решает для ОС? ⭐⭐
- Что такое swap и в каких случаях его использование помогает, а в каких — «убивает» производительность? ⭐⭐
- Как связаны «страницы памяти», подкачка и то, что программа может адресовать больше, чем физическая RAM? ⭐⭐⭐
- Как бы вы интерпретировали вывод `free -h` и `vmstat`: какие поля укажут на активную подкачку и дефицит памяти? ⭐⭐⭐
- Почему виртуальная память упрощает код прикладных программ, а не только «даёт больше памяти»? Приведите пример. ⭐⭐⭐

## Файловые системы: пути, каталоги, операции

- Почему файловая система считается ключевой абстракцией ОС, и какие детали устройств она скрывает? ⭐⭐
- Объясните разницу между абсолютным и относительным путём и роль текущего рабочего каталога процесса. ⭐
- Как устроена иерархия каталогов как «дерево», и какие преимущества даёт по сравнению с одноуровневой директорией? ⭐⭐
- Почему операции `open/read/write/close` считаются «минимальным набором» для работы с данными? Что строится поверх них? ⭐⭐
- Чем отличается удаление файла от удаления каталога (`rm` vs `rmdir`), и почему каталог нельзя удалить, пока он не пуст? ⭐⭐
- Что такое монтирование и почему модель «единое дерево» отличается от «букв дисков» в Windows? ⭐⭐
- Объясните роль `/dev` и смысл «специальных файлов»: что это даёт ОС и приложениям? ⭐⭐
- Что такое pipe в терминах потока данных: почему он выглядит как файл, но ведёт себя иначе? ⭐⭐
- Зачем существуют `/dev/stdout` и `/dev/null`: какие практические сценарии они упрощают? ⭐

## Базовые понятия: процесс, программа, абстракция ОС, параллелизм

- Что такое **процесс** с точки зрения операционной системы, и какие компоненты состояния отличают его от «просто программы на диске»? ⭐
- Объясните разницу между понятиями **программа** и **процесс** на примере одного исполняемого файла, запущенного несколько раз. ⭐
- Почему процесс называют **ключевой абстракцией ОС**, и какие механизмы ОС вокруг него построены? ⭐⭐
- Что означает идея **«виртуального CPU»** для процесса, и за счёт чего ОС создаёт эту иллюзию? ⭐⭐
- Какие ресурсы процесса можно считать **логическими**, а какие — **физическими**, и как ОС разделяет эти уровни? ⭐⭐⭐
- Какие свойства процесса делают его удобной единицей **изоляции и безопасности** в системе? ⭐⭐
- В каких случаях процессы в системе **не являются пользовательскими программами**, а служат инфраструктурой ОС? ⭐⭐
- Объясните, что такое **псевдопараллелизм** на одном ядре и почему пользователь воспринимает его как «одновременность». ⭐
- Чем принципиально отличается псевдопараллелизм от **реального параллелизма** на многоядерной системе? ⭐
- Почему в многозадачной системе **скорость выполнения** отдельного процесса становится плохо предсказуемой? ⭐⭐
- Почему **busy-wait / idle loops** — плохой способ тайминга в ОС с вытесняющей многозадачностью? ⭐⭐
- Какие механизмы нужны системе, чтобы поддерживать задачи **реального времени**, и почему «обычное планирование» часто не подходит? ⭐⭐⭐
- Как мультипрограммирование связано с тем, что процессы часто находятся в состоянии **ожидания I/O**? ⭐⭐

## Создание процессов: UNIX fork/exec и Windows CreateProcess

- Перечислите основные ситуации, когда в системе **создаются процессы** (boot, пользователь, родитель, batch) и объясните их отличия. ⭐
- Почему в UNIX исторически сложилась двухшаговая модель **fork() → exec()**, и какие преимущества она даёт? ⭐⭐
- Что именно копирует fork() и что **не копируется**? ⭐⭐
- Что такое **copy-on-write** и почему он делает fork эффективным в реальных ОС? ⭐⭐⭐
- В чём смысл «окна» между fork() и exec() для shell-подобных программ? Приведите примеры действий, которые выполняются именно там. ⭐⭐
- Что делает execve()/execvp() на уровне процесса, и почему говорят «заменяет образ процесса»? ⭐⭐
- Почему в Windows используют **CreateProcess** вместо fork/exec, и какие возможности он даёт сразу при запуске? ⭐⭐
- Какие типичные ошибки делают при работе с CreateProcess (например, командная строка, наследование дескрипторов, ожидание завершения)? ⭐⭐⭐
- Объясните, зачем родителю ждать дочерний процесс (waitpid / WaitForSingleObject), и что может случиться, если этого не делать. ⭐⭐
- Какие бывают причины завершения процесса и чем отличается «ошибка программы» от «принудительного убийства»? ⭐
- Чем отличается **exit-код** процесса от завершения **сигналом**, и почему ОС должна уметь различать эти сценарии? ⭐⭐
- Как родитель в UNIX может определить: ребёнок завершился нормально или был убит сигналом? ⭐⭐
- Что означает «завершение родителя ≠ завершение детей» и какие последствия это имеет для архитектуры сервисов? ⭐⭐
- Почему в многопользовательской системе нельзя разрешать «кому угодно» завершать чужие процессы? Какие механизмы авторизации обычно применяются? ⭐⭐⭐
- Почему fork в C++ может «ломать» привычный жизненный цикл объектов, и какие классы проблем это порождает? ⭐⭐
- Объясните разницу между `exit()` и `_exit()` в дочернем процессе после fork, и почему неправильный выбор может приводить к багам. ⭐⭐⭐
- Приведите примеры ресурсов (файлы, сокеты, lock-файлы, логи), которые после fork могут привести к ошибкам, и предложите стратегии безопасного дизайна. ⭐⭐⭐

## Идентификаторы и дескрипторы, управление процессами

- Что такое PID и какие свойства у него есть (уникальность, переиспользование, область видимости)? ⭐
- В чём отличие PID от HANDLE: почему PID — это «паспорт», а HANDLE — «ключ»? ⭐⭐
- Какие операции обычно можно выполнить, имея только PID, и какие требуют более «сильной ссылки» на объект? ⭐⭐
- Почему в Windows объект ядра может продолжать существовать после завершения процесса, и что определяет момент его уничтожения? ⭐⭐⭐
- Объясните, как в Linux соотносятся PID, TID и TGID, и почему главный поток имеет PID = TID. ⭐⭐
- Как формируется **дерево процессов** в UNIX, и почему процесс PID 1 играет особую роль? ⭐⭐
- Что такое процесс-группа и зачем она нужна в терминальной работе (например, Ctrl-C)? ⭐⭐
- Почему говорят, что Windows «не хранит дерево процессов так же жёстко», как UNIX, и какие практические последствия у этого есть? ⭐⭐
- Что такое «потеря иерархии» при передаче HANDLE другому процессу в Windows, и почему это меняет модель управления? ⭐⭐⭐
- Опишите модель состояний процесса: **Running / Ready / Blocked**. Что означает каждое состояние на практике? ⭐
- Разберите переходы между состояниями: какие из них вызваны **внешними событиями**, а какие — решениями **планировщика**? ⭐⭐
- Почему процесс может быть Ready, но не Running, и какие факторы влияют на то, когда он получит CPU? ⭐⭐
- На примере pipeline `cat | grep` объясните, почему один процесс может быть Blocked, а другой — Running/Ready, и как это связано с I/O. ⭐⭐
- Чем отличается блокировка на I/O от «просто ожидания кванта времени» с точки зрения эффективности системы? ⭐⭐⭐
- Что такое **PCB (Process Control Block)** и какие данные в нём критичны для переключения контекста? ⭐⭐
- Почему таблица процессов — это не просто список, а центральная структура для планировщика, сигналов, памяти и файлов? ⭐⭐⭐
- Опишите, что происходит при **переключении контекста**: какие части состояния сохраняются и где именно. ⭐⭐⭐
- Почему процесс может быть прерван тысячи раз, но «не замечать этого»? Какие условия должны соблюдаться для этой иллюзии? ⭐⭐
- Как связаны понятия **прерывание**, **обработчик**, **вектор прерываний** и последующее решение планировщика? ⭐⭐⭐
- Что такое `task_struct` в Linux и почему его считают «сердцем» модели процессов? ⭐⭐⭐

## Классическая модель потока

- Чем поток принципиально отличается от процесса с точки зрения модели ОС и программиста? ⭐
- Почему потоки называют «процессом внутри процесса» — что именно “внутри”, а что “общее”? ⭐⭐
- Какие типы задач выигрывают от потоков, а какие — почти не выигрывают? Приведите примеры. ⭐⭐
- Объясните идею перекрытия I/O и вычислений на примере: что означает «CPU не простаивает»? ⭐⭐
- Почему создание/уничтожение потоков обычно дешевле, чем процессов? За счёт каких ресурсов/операций? ⭐⭐
- В каких случаях многопоточность может ухудшить производительность по сравнению с однопоточной программой? ⭐⭐⭐
- Какие сущности относятся к «ресурсам процесса», а какие — к «контексту исполнения потока»? ⭐
- Почему процесс называют «единицей управления ресурсами», а поток — «единицей планирования»? ⭐⭐
- Какие ресурсы *обычно* общие для потоков одного процесса, а какие — строго индивидуальные? ⭐⭐
- Что именно хранится в «контексте потока», который требуется для переключения? ⭐⭐
- Как наличие общего адресного пространства упрощает взаимодействие потоков по сравнению с процессами? ⭐
- Почему отсутствие защиты между потоками делает ошибки опаснее, чем при IPC между процессами? ⭐⭐

## Параллелизм и планирование, ресурсы потока

- Чем псевдопараллелизм на одном CPU отличается от реального параллелизма на многоядерной системе? ⭐
- Как ОС решает, какой поток получит CPU следующим (в общих чертах)? ⭐⭐
- Что означают состояния running/ready/blocked/terminated для *потока*, и как они соотносятся с состояниями процессов? ⭐⭐
- Приведите пример перехода thread: running → blocked и объясните, почему это не «ошибка планировщика». ⭐⭐
- В каких ситуациях полезен добровольный yield, и почему он не гарантирует немедленного переключения? ⭐⭐
- Какие метрики/сигналы в системе вы бы смотрели, чтобы понять: приложение ограничено CPU или I/O? ⭐⭐⭐
- Почему у каждого потока должен быть собственный стек? Что сломается при «общем стеке»? ⭐⭐
- Что такое «кадры стека» и почему их структура важна для понимания выполнения потока? ⭐
- Какие данные разделяются потоками в куче/глобальной области, а какие — «живут» на стеке каждого потока? ⭐⭐
- Приведите пример ошибки, когда адрес локальной переменной передают в поток, и объясните причину. ⭐⭐
- Как различается типичная отладка багов «повреждение стека» vs «гонка данных» (на уровне симптомов)? ⭐⭐⭐
- Что означает «ядро не в курсе потоков» в user-level модели, и как библиотека переключает потоки? ⭐⭐
- Почему блокирующий системный вызов (например, read) блокирует **весь процесс** при user-level threads? ⭐⭐
- Почему page fault в user-level модели может «заморозить» все user threads, даже если они логически независимы? ⭐⭐⭐
- Какие обходные решения позволяют делать user-level потоки практичнее (select/poll/epoll, wrapper’ы), и чем они платят? ⭐⭐⭐
- В чём ключевые преимущества kernel threads над user-level threads, и какие накладные расходы они добавляют? ⭐⭐
- Объясните гибридную модель M:N: что планирует ОС, что планирует рантайм, и почему это похоже на goroutines/виртуальные потоки. ⭐⭐⭐

## Жизненный цикл потоков и базовые примитивы

- Опишите типичный жизненный цикл: create → работа → join. Какие ошибки бывают на каждом этапе? ⭐⭐
- Что произойдёт, если не вызвать join/detach для std::thread, и почему стандарт выбрал именно такое поведение? ⭐⭐
- Чем joinable поток отличается от detached (концептуально и по последствиям для ресурсов)? ⭐⭐
- Какие стратегии завершения потоков вы бы применили в сервере: «жёстко убить», «кооперативно остановить», «дождаться» — и почему? ⭐⭐⭐
- Почему важно проектировать «владение задачей» и «владение потоком» отдельно? ⭐⭐⭐
- Объясните назначение pthread_create: какие параметры критичны и почему start_routine имеет сигнатуру void* (void*)? ⭐⭐
- Почему нельзя передавать &i (адрес переменной цикла) как arg в pthread_create? Объясните, когда это «случайно работает». ⭐⭐
- Что делает pthread_join, и какие типичные ошибки приводят к EINVAL/EDEADLK/ESRCH? ⭐⭐⭐
- Зачем существуют pthread_attr_* и какие атрибуты вы бы реально настраивали в практике? ⭐⭐
- Что такое размер стека потока, чем опасен слишком маленький стек, и почему есть PTHREAD_STACK_MIN? ⭐⭐
- Когда вы бы использовали sched_yield, и почему он не является «средством синхронизации»? ⭐⭐
- Почему для программ с C/C++ runtime в Windows рекомендуют _beginthreadex, а не CreateThread? ⭐⭐
- Какие проблемы могут проявиться при CreateThread в программе, активно использующей CRT (printf/malloc/iostream), и почему? ⭐⭐⭐
- Зачем CloseHandle после завершения потока и почему его не делает _endthreadex? ⭐⭐
- Чем отличается HANDLE от thread id (TID) с точки зрения управления потоком? ⭐⭐
- Как бы вы организовали ожидание нескольких потоков в Windows и какие ограничения/нюансы у WaitForMultipleObjects? ⭐⭐⭐
- Сравните std::thread и std::jthread: какие риски снижает jthread и какой ценой? ⭐⭐
- Почему «RAII для потока» в виде std::jthread — важная идея для надёжности? ⭐⭐
- Объясните идею кооперативной отмены через std::stop_token: что должно делать тело потока? ⭐⭐
- Что произойдёт в примере с SortVector, если **не сохранять** возвращаемый std::jthread в переменную? Почему? ⭐⭐⭐

  ```cpp
  template <typename T>
  std::jthread SortVector(std::vector<T>& values) {
    return std::jthread{ [&values] {
      std::ranges::sort(values);
    } };
  }

  int main()
  {
    std::vector<int> numbers{ 10, 2, -5, 3, 17, 5 };
    std::vector<std::string> strings{ "one", "two", "three", "four", "five" };
    {
      auto t1 = SortVector(numbers); // Что если не сохранять результат в переменную?
      auto t2 = SortVector(strings);
    }
  }
  ```

- В каких случаях вы бы предпочли std::thread вместо std::jthread? ⭐⭐⭐

## Базовые понятия IPC и синхронизации

- Чем принципиально отличаются **синхронизация** и **коммуникация** между процессами/потоками?
   Приведите примеры, где нужна только одна из них, и где нужны обе. ⭐⭐
- Почему общая память «упрощает обмен данными», но одновременно «усложняет синхронизацию»? Разберите на примере инварианта структуры данных. ⭐⭐
- Дайте определения: **race condition**, **data race**, **atomicity violation**. Чем они отличаются и как проявляются? ⭐⭐⭐
- Что такое **критическая секция**? Какие свойства кода/ресурса делают участок «критическим»? ⭐
- Какие 4 условия корректного решения задачи критической секции (mutual exclusion) вы считаете ключевыми, и почему каждое из них важно на практике? ⭐⭐
- Почему пример с `counter++/counter--` на двух потоках может дать «случайный» результат, хотя на вид код симметричен? Опишите возможные межпоточные интерливинги. ⭐⭐

  ```cpp
  void Increment(int& counter) { ++counter; }
  void Decrement(int& counter) { --counter; }
  
  int main() {
    int counter = 0;
    std::jthread t1{ [&counter] {
    for (int i = 0; i < 1'000'000'000; ++i)
      Increment(counter);
    } };
    std::jthread t2{ [&counter] {
    for (int i = 0; i < 1'000'000'000; ++i)
      Decrement(counter);
    } };
    t1.join(); t2.join();
    std::cout << "Counter: " << counter << '\n';
  }
  ```

- Объясните, как исправить проблему в коде выше. ⭐⭐
- Что означает префикс `lock` в x86-инструкциях (например, `lock add`)? Как это связано с когерентностью кэша и «атомарностью»? ⭐⭐⭐
- Почему `volatile` **не является** механизмом синхронизации в C++? Приведите пример, где `volatile` не спасает от гонки. ⭐⭐⭐
- Объясните смысл **acquire/release** на примере «данные + флаг готовности». Что такое *happens-before*? ⭐⭐⭐

## Классические алгоритмы синхронизации

- Почему **busy waiting** считается проблемой в пользовательских программах? Назовите минимум 3 причины. ⭐
- Почему «запрет прерываний» работает как механизм взаимного исключения на одноядерной системе, и почему ломается на SMP? ⭐⭐
- Чем отличается «запрет прерываний» от «атомарной инструкции с блокировкой шины/кэша» с точки зрения охвата других CPU? ⭐⭐
- Почему инструкции `CLI/STI` недоступны в ring 3 и что произойдёт при попытке выполнить их в user mode? ⭐⭐
- В каких случаях ядро ОС всё же использует отключение прерываний, и почему время удержания должно быть «считанные инструкции»? ⭐⭐⭐
- Почему «простая lock-переменная» не обеспечивает взаимного исключения? Опишите гонку пошагово. ⭐
- Почему «прочитать lock дважды» не решает проблему? Сформулируйте, какая именно гарантия отсутствует. ⭐
- Что такое **Strict Alternation** и в чём его ключевой дефект с точки зрения требований к критической секции? ⭐⭐
- Приведите сценарий, где Strict Alternation блокирует процесс, хотя критическая секция свободна. Почему это плохо для производительности? ⭐⭐
- Можно ли «починить» Strict Alternation без аппаратной атомарности? Если да — какой ценой; если нет — почему? ⭐⭐⭐
- Объясните идею алгоритма Петерсона: зачем нужны **interested[]** и **turn** одновременно? ⭐⭐
- Докажите (словами) хотя бы одно свойство: mutual exclusion / progress / bounded waiting для алгоритма Петерсона. ⭐⭐⭐
- Почему реализация Петерсона на обычных `bool/int` может ломаться на современных CPU? ⭐⭐⭐
- Почему добавление `volatile` всё равно может не исправить Петерсона в C++? Что именно `volatile` гарантирует и чего не гарантирует? ⭐⭐⭐
- Как корректно реализовать Петерсона в C++ с `std::atomic`? Какие memory order’ы уместны и почему? ⭐⭐⭐

## Спинлоки

- Что делает TSL (test-and-set) и почему эта операция считается атомарной? ⭐⭐
- Сравните TSL и XCHG как примитивы: в чём концептуальная одинаковость и какие есть архитектурные нюансы. ⭐⭐
- Почему спинлоки эффективны только для «очень коротких» критических секций? Опишите критерии «короткости». ⭐⭐
- Что такое **starvation** в контексте спинлоков и почему отсутствие fairness — нормальная цена за простоту? ⭐⭐
- Какие техники применяют, чтобы уменьшить вред спина под конкуренцией (pause/yield/backoff)? Почему это помогает? ⭐⭐⭐
- Объясните, как `atomic_flag::test_and_set` реализует идею TSL. Что возвращает и почему это удобно для лока? ⭐⭐
- Почему в примере используются `memory_order_acquire` на lock и `memory_order_release` на unlock? Что будет, если поставить `relaxed`? ⭐⭐⭐
- Какие практические проблемы у такого спинлока: рекурсивность, fairness, влияние на энергопотребление, масштабирование на много ядер? ⭐⭐
- Почему внутри `std::atomic_flag` реализация может быть сложнее, чем кажется? Как это влияет на производительность? ⭐⭐⭐
- Как бы вы добавили в TSLLock `try_lock()` и «вежливое ожидание»? Какие компромиссы появятся? ⭐⭐

## Спинлоки в ядре: IRQ и вытеснение

- Зачем ядру нужно различать `spin_lock`, `spin_lock_irq` и `spin_lock_irqsave`? Опишите типичный сценарий для каждого. ⭐⭐⭐
- Почему «спать» внутри спинлока нельзя? Приведите пример deadlock-сценария. ⭐⭐
- В чём опасность, если обработчик прерывания попытается захватить тот же спинлок на том же CPU? Как это предотвращают? ⭐⭐⭐
- Почему `spin_lock_irq` может быть быстрее `irqsave`, но потенциально опаснее? ⭐⭐
- Что происходит с латентностью прерываний, если слишком часто/долго держать spin_lock_irqsave? Чем это грозит системе? ⭐⭐⭐
- В чём фундаментальная проблема примитивов `sleep()`/`wakeup()` как абстракции, если нет «памяти о сигнале»? ⭐⭐
- Разберите сценарий «потерянного wakeup» в producer-consumer из слайдов: какие именно шаги приводят к вечному сну? ⭐⭐⭐
- Почему «wakeup waiting bit» решает проблему только для двух процессов и начинает ломаться при увеличении числа участников? ⭐⭐⭐
- Как связаны sleep/wakeup, очереди ожидания и «ожидание по адресу» (sleep(address)/wakeup(address))? Почему привязка к адресу полезна? ⭐⭐
- Чем отличаются «sleep как задержка по времени» (nanosleep) и «sleep как IPC/синхронизация»? Почему путаница опасна? ⭐⭐
- Семафор как «счётчик сохранённых wakeup’ов»: объясните модель и почему она предотвращает потерю сигналов. ⭐⭐
- Почему операции `down/up` в семафоре должны быть атомарными? Что именно должно быть «неделимо» и какая гонка иначе появится? ⭐⭐⭐
- В задаче producer-consumer объясните роль трёх семафоров `mutex/empty/full` как **двух разных применений**: mutual exclusion vs ordering. ⭐⭐
- Сравните `std::counting_semaphore` и `std::condition_variable` как инструменты синхронизации: где проще семафор, а где — condvar? ⭐⭐⭐
- Как бы вы спроектировали ограничитель ресурсов (например, «не больше K одновременных запросов») в C++20: какие примитивы выберете и какие corner cases учтёте? ⭐⭐⭐

## Мьютексы: идея и реализация

- Почему мьютекс называют «упрощённым семафором»? В каких задачах семафор принципиально сильнее мьютекса? ⭐⭐
- Какие ошибки синхронизации мьютекс предотвращает, а какие **не предотвращает** (например, логические гонки и нарушение инвариантов)? ⭐⭐
- Объясните, почему «достаточно 1 бита», но на практике состояние мьютекса хранится как целое число/слово. ⭐⭐
- Разберите реализацию `mutex_lock` через TSL: что происходит при конкуренции, и почему используется `thread_yield()`? ⭐⭐
- Чем подход `mutex_lock + yield` отличается от чистого спинлока? Когда yield ухудшает ситуацию? ⭐⭐⭐
- Зачем нужен `trylock()`? Приведите пример алгоритма, где `trylock` позволяет избежать дедлока или улучшить latency. ⭐⭐
- Почему мьютексы «естественно» работают для потоков, но требуют дополнительных механизмов для процессов? ⭐⭐
- Какие способы межпроцессного мьютекса возможны: ядровые объекты, shared memory, файлы? Какие у каждого плюсы/минусы? ⭐⭐⭐
- Какие свойства должен иметь мьютекс, чтобы быть безопасным для межпроцессной синхронизации? ⭐⭐⭐
- Почему «мьютекс в user space» обычно быстрее, чем ядровая блокировка, и в каких случаях это перестаёт быть правдой? ⭐⭐⭐

## Futex и condition variables

- Какую проблему выбора «spinlock vs блокировка через ядро» решает futex? ⭐⭐
- Объясните, что означает «в отсутствии конкуренции ядро не вовлекается вообще». За счёт чего это достигается? ⭐⭐⭐
- Опишите жизненный цикл захвата futex: атомарная попытка → системный вызов → очередь ожидания → пробуждение. ⭐⭐⭐
- Почему futex редко используется напрямую прикладным программистом, но часто встречается «под капотом»? ⭐⭐
- Какие ошибки могут возникнуть при неправильном использовании futex (например, потерянные пробуждения, ABA-сценарии, неверные ожидания)? ⭐⭐⭐
- Какие гарантии даёт `pthread_mutex_lock` и что он НЕ гарантирует (например, порядок пробуждений/справедливость)? ⭐⭐
- Почему условные переменные всегда используются **вместе с мьютексом**? ⭐⭐
- Что означает фраза «условные переменные не накапливают сигналы» и чем это отличается от семафоров? ⭐⭐⭐
- Объясните, почему `pthread_cond_wait(&cond, &mutex)` атомарно «отпускает мьютекс и засыпает». Почему это важно? ⭐⭐⭐
- В producer/consumer примере почему проверка условия должна быть в `while`, а не `if`? Назовите минимум две причины. ⭐⭐
- Чем отличаются `std::lock_guard` и `std::unique_lock`? Почему `wait()` требует именно `unique_lock`? ⭐⭐
- Что такое spurious wakeup и почему он возможен даже при корректной логике notify? ⭐⭐⭐
- В чём разница между `cv.wait(lock)` и `cv.wait(lock, predicate)` с точки зрения безопасности и читаемости? ⭐⭐
- Какую типичную ошибку делают при использовании `notify_one()`/`notify_all()` (например, уведомление без изменения состояния)? ⭐⭐
- Опишите корректный дизайн очереди producer-consumer на C++: где хранится условие, где мьютекс, где уведомление, что защищаем. ⭐⭐⭐

## std::mutex и разновидности мьютексов

- В каких случаях оправдан `std::recursive_mutex`, и почему его часто считают «запахом дизайна»? ⭐⭐⭐
- Чем полезны `std::timed_mutex` и таймауты в синхронизации? Приведите пример, где таймаут — часть корректности. ⭐⭐⭐
- Почему RAII-обёртки (lock_guard/unique_lock) уменьшают вероятность дедлоков и утечек блокировки? ⭐⭐
- Какие риски возникают, если внутри критической секции делать I/O или ждать другие ресурсы? ⭐⭐
- Какие способы избежать дедлоков при захвате нескольких мьютексов (lock ordering, std::lock, try_lock loop)? ⭐⭐⭐
- Чем `std::shared_mutex` принципиально отличается от обычного `std::mutex` по модели допуска потоков? ⭐⭐
- В каких сценариях `std::shared_mutex` реально ускоряет систему, а в каких может замедлить? ⭐⭐
- Почему стандарт не гарантирует справедливость в `std::shared_mutex` и к чему это приводит для писателей? ⭐⭐⭐
- Почему upgrade (shared → unique) небезопасен без выхода? Опишите гонку, которая возникает при «наивном апгрейде». ⭐⭐⭐
- Почему `shared_mutex` подходит только для коротких критических секций, несмотря на «параллельность чтения»? ⭐⭐

## FairRWLock и мониторы

- В чём идея writer-preferred RWLock и как она предотвращает starvation писателей? ⭐⭐
- Какие поля нужны FairRWLock (active readers / waiting writers / active writer) и какие инварианты они должны соблюдать? ⭐⭐⭐
- Почему в `lock_shared()` читатели должны ждать не только `active_writer == false`, но и `waiting_writers == 0`? ⭐⭐⭐
- Объясните логику пробуждений: почему в `unlock()` иногда будим писателя, а иногда всех читателей? ⭐⭐⭐
- Какие типичные ошибки приводят к дедлоку или «зависанию» в RWLock (например, неверный notify, неправильные условия ожидания)? ⭐⭐⭐
- Почему мониторы появились как реакция на «опасность семафоров»? Какие классы ошибок они уменьшают? ⭐⭐
- Что означает «только один поток активен в мониторе» и как это реализуется на практике (на уровне языка/рантайма)? ⭐⭐
- Сравните семантику сигнализации Хоара и Бринч Хансена: кто продолжает выполнение после `signal()` и почему это важно. ⭐⭐⭐
- Почему даже в мониторах сигналы condition variables «не копятся»? Какие последствия это имеет для дизайна? ⭐⭐⭐
- Как модель монитора в Java (`synchronized`, `wait/notify`) отличается от «классического» монитора с отдельными condition variables? ⭐⭐⭐
- Какие проблемы появляются при IPC через сообщения в распределённой среде: потери, дубликаты, порядок, подмена отправителя? ⭐⭐
- Зачем нужны ACK + ретрансляции и почему это сразу приводит к необходимости sequence numbers? ⭐⭐⭐
- Чем отличается адресация «процесс → процесс» от mailboxes? Как mailboxes помогают масштабировать систему? ⭐⭐
- Сравните rendezvous (без буфера) и буферизированный обмен: какие плюсы/минусы по latency, throughput и сложности? ⭐⭐⭐
- Объясните producer–consumer без общей памяти через «пустые/полные» сообщения: какой инвариант делает систему корректной? ⭐⭐⭐

## Барьеры синхронизации (phase synchronization), ошибки работы с многопоточностью

- Объясните, чем барьер отличается от мьютекса/семафора: какую задачу он решает и какую — нет? ⭐⭐
- В каких типах алгоритмов барьер является «естественным» примитивом, и почему там нельзя просто поставить мьютекс? ⭐⭐
- Что означает «никто не переходит к фазе n+1, пока все не закончили фазу n» в терминах корректности данных между итерациями? ⭐⭐
- Как устроен переиспользуемый барьер: зачем нужны счётчик участников и «поколение»? ⭐⭐⭐
- Объясните, какую роль играет `completion step` в `std::barrier`, и приведите пример, где без него легко ошибиться. ⭐⭐⭐
- Какие ошибки приводят к дедлоку на барьере, и какие стратегии защиты применяют промышленные реализации? ⭐⭐⭐
- Что такое «straggler» и почему он может полностью «убить» производительность параллельного цикла, даже если барьер реализован идеально? ⭐⭐
- Объясните паттерн «current/next + swap на барьере»: какие гонки он предотвращает и почему это лучше, чем писать в один и тот же массив. ⭐⭐⭐

  ```cpp
  std::barrier sync(N, [&]{
    std::swap(current, next);
  });

  void worker(chunk c) {
    for (int it=0; it<steps; ++it) {
      compute(next, current, c);  // читаем из current, пишем в next
      sync.arrive_and_wait();
    }
  }
  
  ```

- В каких ситуациях двойная буферизация не спасает и что тогда делают? ⭐⭐⭐
- Какие инварианты должны выполняться на границе итерации, чтобы следующий шаг не увидел «смешанные» данные? ⭐⭐
- Почему нельзя путать синхронизационный барьер (group barrier) и memory fence? Приведите пример, где один нужен, а другой — нет. ⭐⭐⭐
- Опишите сценарий, когда из-за out-of-order execution «флаг готовности» становится видимым раньше данных, и к чему это приводит. ⭐⭐
- Объясните, как пара `store(..., release)` и `load(..., acquire)` обеспечивает корректную публикацию данных (happens-before). ⭐⭐⭐
- В примере с `turn` и `x`: почему `x` можно читать `relaxed`, но всё равно гарантированно увидеть 100 после `acquire` на `turn`? ⭐⭐⭐
  
  ```cpp
  std::atomic<int> turn{0};
  std::atomic<int> x{0};
  
  // writer:
  x.store(100, std::memory_order_relaxed);
  turn.store(1, std::memory_order_release); // публикуем флаг ПОСЛЕ данных

  // reader:
  while (turn.load(std::memory_order_acquire) != 1) { /* spin */ }
  int v = x.load(std::memory_order_relaxed); // видим 100 гарантированно  
  ```

- В каких случаях уместно использовать `std::atomic_thread_fence`, а когда лучше выразить зависимость через acquire/release на конкретных атомиках? ⭐⭐⭐
- Разберите по шагам механизм инверсии приоритетов с потоками L/M/H: почему наличие «среднего» приоритета делает ситуацию хуже? ⭐⭐⭐
- Сравните Priority Inheritance и Priority Ceiling: что они гарантируют, какие вводят накладные расходы и какие риски/сложности (например, цепочки наследования или настройка потолков)? ⭐⭐⭐
- Почему «отключить прерывания» — плохое решение для пользовательского кода и непереносимая стратегия для общей синхронизации? ⭐⭐

## Планирование процессов, контекст планирования

- Объясните, почему в многопрограммной системе вообще возникает необходимость планирования CPU, и чем «ready state» отличается от «running» и «blocked». ⭐
- В чём разница между планировщиком и алгоритмом планирования? Приведите примеры решений, которые принимает планировщик. ⭐
- Почему принципы планирования применимы не только к процессам, но и к потокам? Что меняется, когда планируем потоки вместо процессов? ⭐⭐
- Сравните роль планирования в пакетных системах, на персональных компьютерах и на серверах. Почему важность планирования так различается? ⭐⭐
- Приведите примеры сценариев, где планирование становится критичным даже на «быстром» компьютере (рендеринг, игры и т. п.). Что именно в нагрузке делает планирование важным? ⭐⭐
- Почему в IoT/смартфонах планирование тесно связано с энергопотреблением? Какие компромиссы при этом возникают? ⭐⭐
- Опишите, что происходит при context switch на уровне CPU и ОС (режим ядра, регистры, память, кэши). Почему это «дорого»? ⭐⭐
- Какие компоненты накладных расходов переключения контекста зависят от архитектуры памяти (MMU, TLB) и кэширования? ⭐⭐
- Почему слишком частые переключения процессов могут снижать реальную полезную производительность системы даже при высокой загрузке CPU? ⭐⭐
- Как выбор длины кванта (time slice) влияет на долю времени, теряемую на переключения? Объясните на качественном уровне. ⭐⭐
- Какие метрики или симптомы в системе могут указывать, что накладные расходы на переключения стали чрезмерными? ⭐⭐⭐

## Виды процессов и их планирование

- Дайте определение CPU burst и I/O burst. Почему ключевым фактором для классификации CPU-bound/I/O-bound считается длина CPU burst? ⭐
- Приведите примеры типичных CPU-bound и I/O-bound задач в современных ОС и объясните их поведение через bursts. ⭐⭐
- Почему ускорение CPU в исторической перспективе «делает процессы более I/O-bound»? Какие технологические причины лежат в основе? ⭐⭐
- Объясните, почему для производительности системы важно «смешивать» CPU-bound и I/O-bound процессы (баланс CPU и устройств). ⭐⭐
- Что будет происходить с загрузкой CPU и диска, если в памяти окажутся только CPU-bound задачи, а затем только I/O-bound? Почему это плохо? ⭐⭐
- Как выбор алгоритма планирования может улучшать «параллелизм» CPU и I/O в системе? Приведите пример стратегии для I/O-bound процессов. ⭐⭐⭐
- Перечислите основные события, в которых ОС может принять решение о перепланировании (создание, завершение, блокировка, I/O interrupt, таймер). Почему этих событий достаточно? ⭐⭐
- В чём принципиальная разница между preemptive и nonpreemptive планированием? Какие риски есть у каждого подхода? ⭐⭐
- Почему наличие периодических прерываний таймера критично для вытесняющего планирования? Что произойдёт, если таймера нет? ⭐⭐
- Объясните, почему вытесняющая многозадачность важна не только для приложений, но и для ядра (preemptive kernel). ⭐⭐
- Приведите пример ситуации, когда невытесняющее планирование может выглядеть привлекательным, и объясните, чем это может обернуться в реальной системе. ⭐⭐⭐

## Категории систем и цели планирования

- Сравните ключевые цели планирования для batch, interactive и real-time систем. Почему одна и та же метрика не подходит всем? ⭐⭐
- Что такое fairness в планировании? Как «справедливость» может конфликтовать с производительностью или политикой приоритетов? ⭐⭐⭐
- Объясните разницу между throughput и turnaround time. Почему максимизация throughput может ухудшать turnaround? ⭐⭐
- Почему CPU utilization — спорная метрика качества планирования в batch-системах? Когда она всё же полезна? ⭐⭐
- Что такое response time в интерактивных системах и почему «пропорциональность ожиданиям пользователя» важна как отдельная цель? ⭐⭐
- Почему в real-time системах «правильный ответ слишком поздно» может быть эквивалентен ошибке? Приведите примеры. ⭐⭐
- Чем отличается predictability от просто «высокой скорости» в real-time/мультимедиа? Почему jitter критичен? ⭐⭐⭐
- Опишите алгоритм FCFS и объясните, почему его называют «справедливым», но при этом он может давать плохую среднюю производительность. ⭐⭐
- Что такое «эффект конвоя» в FCFS? Опишите сценарий с CPU-bound и множеством I/O-bound процессов и последствия для времени завершения. ⭐⭐⭐
- Объясните идею SJF (Shortest Job First) и почему он минимизирует среднее turnaround time при известной длительности задач. ⭐⭐
- В каких условиях SJF является оптимальным, а в каких — нет? Приведите контрпример с разными временами прихода задач. ⭐⭐⭐
- Чем SRTN (Shortest Remaining Time Next) отличается от SJF и почему вытеснение помогает «коротким» задачам? ⭐⭐
- Какие практические проблемы возникают при попытке применить SJF/SRTN в реальных ОС (оценка времени, ошибки прогнозов, starvation)? ⭐⭐⭐

## Интерактивные системы: Round Robin и приоритеты

- Опишите работу Round Robin и объясните роль кванта времени. Почему RR считают «простым и справедливым»? ⭐⭐
- Как слишком короткий квант влияет на CPU efficiency, а слишком длинный — на response time? Почему диапазон 20–50 мс часто компромиссный? ⭐⭐
- В каких ситуациях RR фактически становится почти невытесняющим? Свяжите это со средним CPU burst. ⭐⭐⭐
- Что такое планирование по приоритетам? Какие реальные причины заставляют ОС вводить приоритеты? ⭐⭐
- Почему приоритетные схемы могут приводить к starvation? Какие механизмы борьбы с этим используются (aging, динамика приоритета и т. п.)? ⭐⭐⭐
- Объясните идею динамического повышения приоритета для I/O-bound процессов. Почему это улучшает общую производительность системы? ⭐⭐⭐
- Почему удобно сочетать приоритеты «между классами» и round robin «внутри класса»? Какие плюсы и минусы у такого гибрида? ⭐⭐
- Опишите идею multiple queues (многоуровневых очередей) и объясните, как они помогают одновременно интерактивным и вычислительным задачам. ⭐⭐
- Почему увеличение кванта на нижних уровнях (1, 2, 4, 8, …) уменьшает число дорогих переключений/свапов в некоторых системах? ⭐⭐⭐
- Приведите пример «обхода» политики многоуровневых очередей пользователем (например, искусственно имитировать интерактивность). Почему «правильно в теории» сложно реализовать на практике? ⭐⭐⭐
- Как можно адаптировать идею SJF к интерактивным системам, если длительности заранее неизвестны? Опишите подход с прогнозированием. ⭐⭐
- Объясните формулу экспоненциального сглаживания (aging) для оценки следующего CPU burst и смысл параметра (a). ⭐⭐⭐
- В чём идея guaranteed scheduling (примерно 1/n CPU каждому) и как измерение «получено vs положено» влияет на выбор следующего процесса? ⭐⭐
- Объясните основную идею Linux CFS на концептуальном уровне: что такое «spent execution time», зачем дерево, почему выбирают «самого недополучившего». ⭐⭐⭐
- Сравните lottery scheduling и fair-share scheduling: что именно считается «справедливостью» в каждом, и в каких сценариях один подход предпочтительнее другого? ⭐⭐⭐

## Планирование в системах реального времени

- Что делает систему «реального времени» отличной от просто «быстрой» системы? Почему «правильный ответ слишком поздно» может считаться ошибкой? ⭐⭐
- Приведите по 2–3 примера hard real-time и soft real-time систем и объясните, что именно является дедлайном в каждом примере. ⭐⭐
- В чём ключевое различие между hard real-time и soft real-time с точки зрения последствий пропуска дедлайна? ⭐⭐
- Почему для мультимедиа-систем важна не только скорость, но и предсказуемость (jitter)? Как планировщик может влиять на качество аудио/видео? ⭐⭐⭐
- Объясните, почему в некоторых real-time системах вытеснение «иногда не требуется». При каких предпосылках это возможно? ⭐⭐⭐
- Сравните периодические и непериодические события в real-time системах. Чем они отличаются с точки зрения планирования и гарантий? ⭐⭐
- Раскройте смысл условия планируемости ($\sum (C_i/P_i) \le 1$). Что означают ($C_i$) и ($P_i$) физически и как интерпретировать сумму? ⭐⭐
- Почему при ($\sum (C_i/P_i) > 1$) система принципиально не может быть корректно запланирована? Какие стратегии остаются в таком случае? ⭐⭐⭐
- В приведённом примере (Периоды: 100/200/500 мс и время обработки 50/30/100 мс) объясните, почему система считается планируемой? ⭐⭐
- В каких реальных ситуациях допущение «накладные расходы на переключение контекста можно игнорировать» становится неверным и как это влияет на проверку планируемости? ⭐⭐⭐
- Предложите метод, как учитывать накладные расходы (context switch, обработка прерываний) при оценке планируемости, не углубляясь в конкретный алгоритм. ⭐⭐⭐
- Почему добавление непериодических задач усложняет гарантии дедлайнов даже при выполнении условия для периодических задач? ⭐⭐⭐
- В чём разница между static scheduling и dynamic scheduling в real-time системах? Какие сведения нужны «заранее» в статическом варианте? ⭐⭐
- Приведите пример системы/сценария, где статическое планирование предпочтительнее, и объясните, почему. ⭐⭐
- Приведите пример системы/сценария, где динамическое планирование неизбежно, и объясните, какую неопределённость оно покрывает. ⭐⭐
- Какие риски и ограничения появляются при статическом планировании, если «идеальная информация заранее» недоступна или ошибочна? ⭐⭐⭐
- Как бы вы объяснили компромисс «предсказуемость vs гибкость» между static и dynamic scheduling на уровне архитектуры системы? ⭐⭐⭐

## Политика против механизма, user-level потоки

- Дайте определения «механизм» и «политика» применительно к планированию. Почему их разделение считается фундаментальным принципом ОС? ⭐⭐
- На примере СУБД объясните, почему приложение может «лучше знать», как планировать свои дочерние задачи/потоки, чем ядро ОС. ⭐⭐
- Приведите примеры параметров/интерфейсов ОС, через которые пользовательский процесс может влиять на политику, не реализуя механизм (приоритеты, квоты и т. п.). ⭐⭐
- Какие опасности возникают, если приложениям дать слишком много контроля над политикой (например, возможность бесконтрольно повышать приоритет)? Как ОС может это ограничивать? ⭐⭐⭐
- Опишите ситуацию, где отсутствие разделения policy/mechanism приводит к заметной потере производительности или нарушению требований по времени. ⭐⭐⭐
- Почему наличие двух уровней параллелизма (процессы и потоки) усложняет планирование по сравнению с «только процессами»? ⭐⭐
- Объясните, как происходит планирование при user-level threads: кто и что планирует, и почему отсутствует принудительное вытеснение потоков таймером? ⭐⭐
- В чём главный практический недостаток user-level threads при блокирующих операциях ввода-вывода? Как он проявляется для пользователя? ⭐⭐
- Объясните, как планирование отличается для kernel-level threads и почему становится возможна «перемежающаяся» последовательность потоков разных процессов. ⭐⭐
- Почему переключение между kernel-level threads обычно дороже, чем между user-level threads? Какие компоненты ОС делают его дорогим? ⭐⭐⭐
- Почему ядру выгоднее (при прочих равных) продолжать выполнять поток в том же процессе, а не переключаться на поток другого процесса? Свяжите ответ с памятью и кэшами. ⭐⭐⭐
- В чём идея гибридного подхода (сочетание user-level и kernel-level) и какие проблемы каждого уровня он пытается компенсировать? ⭐⭐⭐
- Сформулируйте общий вывод лекции для случая real-time + threads: какие свойства планировщика становятся ключевыми (дедлайны, предсказуемость, накладные расходы, политика/механизм) и почему? ⭐⭐⭐

## Память как ресурс

- Почему оперативная память считается одним из ключевых ресурсов системы, и как её нехватка влияет на работу ОС? ⭐
- Объясните, почему «программы растут быстрее, чем объём памяти». Какие причины этого явления вы видите сегодня? ⭐⭐
- Что означает идея «идеальной памяти», и почему она невозможна на практике? ⭐
- Почему компромисс в виде **иерархии памяти** оказался эффективнее попыток сделать один «идеальный» тип памяти? ⭐⭐
- Какие задачи должна решать ОС, чтобы распределять память между процессами справедливо и эффективно? ⭐⭐
- Сравните кеш, RAM и SSD/HDD по скорости, цене и энергозависимости. Почему именно так устроена иерархия? ⭐
- Что означает фраза «ОС должна создать единое абстрактное представление памяти»? ⭐⭐
- Почему доступ к памяти может быть на порядки медленнее, чем операции над регистрами? ⭐⭐
- Как различия во времени доступа (L1/L2/L3/RAM/NUMA/диск) влияют на проектирование программ и алгоритмов? ⭐⭐⭐
- Приведите пример ситуации, когда оптимизация вычислений почти не помогает, потому что узкое место — память. ⭐⭐
- Что такое **менеджер памяти** в ОС и какие функции он обязан выполнять? ⭐
- Почему учёт свободной/занятой памяти является отдельной сложной задачей даже при большом объёме RAM? ⭐⭐
- Почему управление кешем чаще относится к аппаратуре, а не к ОС? ⭐⭐
- Какие ошибки управления памятью могут приводить к падениям программ и всей системы? Приведите примеры. ⭐⭐
- Почему управление памятью часто рассматривают как баланс между производительностью, экономией и предсказуемостью? ⭐⭐⭐

## Память в ранних системах

- Что означает «программа имеет доступ ко всем адресам физической памяти», и почему это опасно? ⭐
- Почему при прямой адресации «две программы не могут существовать в памяти одновременно»? ⭐⭐
- Объясните, как ошибка в одной программе могла уничтожить данные другой программы или ОС в ранних системах. ⭐⭐
- Почему абсолютные адреса в коде делают программу негибкой при загрузке в другое место памяти? ⭐⭐
- Какие преимущества и недостатки имеют системы без виртуальной памяти (например, во встраиваемых устройствах)? ⭐⭐⭐
- Какие варианты размещения ОС в памяти существовали исторически и почему? ⭐⭐
- Почему размещение ОС в RAM без защиты приводило к риску её перезаписи пользователем? ⭐
- Зачем BIOS размещали в ROM в ранних ПК, и какие задачи он решал? ⭐⭐
- Почему даже размещение части ОС в ROM не решало проблему защиты пользовательской памяти полностью? ⭐⭐
- Какие требования к памяти появляются, когда система переходит от «одна программа в памяти» к многозадачности? ⭐⭐⭐
- В чём идея swapping как раннего способа создать иллюзию многозадачности? ⭐⭐
- Как работали аппаратные ключи защиты памяти в IBM/360 и что именно они предотвращали? ⭐⭐⭐
- Почему механизм ключей защиты решал задачу безопасности, но не решал проблему релокации? ⭐⭐
- Что такое PSW и какую роль он играет в контроле доступа к памяти (на концептуальном уровне)? ⭐⭐
- Какие ограничения у схемы защиты памяти «ключами», если сравнивать с полноценными адресными пространствами? ⭐⭐⭐

## Адресные пространства

- Почему при загрузке программы не с нулевого адреса команды перехода/обращения к данным могут «сломаться»? ⭐⭐
- Что такое **статическая релокация**, и как ОС корректирует адреса при загрузке программы? ⭐⭐
- Почему загрузчику важно различать «адрес» и «константу» в машинном коде? ⭐⭐⭐
- Зачем компилятор формирует таблицу релокаций, и что в ней должно быть? ⭐⭐
- Почему статическая релокация делает загрузку медленной и сложной, особенно при частых перемещениях программ? ⭐⭐⭐
- Зачем нужна абстракция памяти и почему без неё сложно обеспечить безопасность и стабильность? ⭐⭐
- Дайте определение адресного пространства процесса и объясните, почему «адрес 28 в одном процессе ≠ адрес 28 в другом». ⭐⭐
- Приведите аналогии адресного пространства с реальными системами (телефонные номера, IP, домены) и объясните их смысл. ⭐
- Как ОС и аппаратное обеспечение совместно сопоставляют виртуальные адреса с физическими? (общая идея) ⭐⭐⭐
- Какие свойства даёт адресное пространство: изоляция, защита, гибкое размещение — и как каждое проявляется? ⭐⭐⭐

## Защита и релокация, swapping

- Объясните принцип работы **base register** и **limit register** и как они обеспечивают защиту процесса. ⭐⭐
- Почему при base/limit программа может «думать», что начинается с адреса 0, даже если в физической памяти она размещена иначе? ⭐⭐
- Что происходит при попытке обращения за пределы limit, и почему это важно для устойчивости системы? ⭐⭐
- Почему изменять base/limit должна иметь право только ОС? Какие угрозы возникают иначе? ⭐⭐⭐
- Какие недостатки у схемы base/limit с точки зрения производительности и почему они проявляются при каждом обращении к памяти? ⭐⭐⭐
- Почему в современных ОС возникает необходимость выгружать процессы на диск, даже при наличии больших объёмов RAM? ⭐⭐
- Опишите полный цикл swapping: загрузка → выполнение → выгрузка → возврат. Какие данные должны сохраняться? ⭐⭐⭐
- Почему при возврате процесса из swap он может оказаться в другом месте памяти, и что нужно для корректной работы? ⭐⭐
- Что такое «дыры» (holes) в памяти и почему swapping усиливает фрагментацию? ⭐⭐
- Объясните, что такое memory compaction, почему она дорогая, и в каких ситуациях может быть оправдана. ⭐⭐⭐

## Управление памятью с помощью битовых карт

- Почему динамическое выделение памяти превращает «свободную память» в отдельный управляемый ресурс ОС? ⭐⭐
- Какие ошибки и сбои возникают, если ОС неправильно ведёт учёт свободных участков памяти? ⭐⭐
- Что такое «учётное представление памяти» и какие требования к нему предъявляются (скорость, точность, надёжность)? ⭐⭐
- Почему задачи учёта свободной памяти похожи на учёт свободных блоков диска в файловой системе? ⭐⭐
- Чем отличаются цели управления памятью **для процессов** и управления памятью **для выделения/освобождения блоков** (allocator-level)? ⭐⭐⭐
- В чём принципиальная разница между внутренней и внешней фрагментацией, и как они проявляются при динамическом выделении? ⭐⭐⭐
- Как выбор стратегии учёта свободной памяти влияет на предсказуемость времени выделения (real-time vs general-purpose)? ⭐⭐⭐
- Как устроена битовая карта свободной памяти и что именно кодирует каждый бит? ⭐
- Что такое **allocation unit** и почему её размер определяет компромисс между расходом памяти на карту и потерями из-за фрагментации? ⭐⭐
- Почему слишком мелкая единица выделения делает карту «большой», но более точной? Какие практические последствия? ⭐⭐
- Почему слишком крупная единица выделения уменьшает размер карты, но увеличивает потери памяти? ⭐⭐
- Объясните на примере, почему поиск «N подряд свободных блоков» в битовой карте может быть медленным. ⭐⭐
- Какие аппаратные/низкоуровневые оптимизации могут ускорить поиск последовательности нулей в битовой карте? ⭐⭐⭐
- Почему битовые карты могут быть «простыми и надёжными», но «не всегда эффективными» для больших динамических систем? ⭐⭐
- В каких сценариях битовая карта может быть предпочтительнее связного списка (по нагрузке, паттерну выделений, требованиям к памяти)? ⭐⭐⭐

## Управление памятью на основе списков сегментов

- Как устроено представление памяти в виде списка сегментов (P/H), и какие поля должны храниться в узле списка? ⭐
- Почему список обычно сортируют по адресу, а не по размеру? Какие операции это упрощает? ⭐⭐
- Зачем при освобождении памяти нужно выполнять **слияние соседних дыр (merge)**, и что произойдёт, если его не делать? ⭐⭐
- Почему двусвязный список часто удобнее однонаправленного в менеджере памяти? ⭐⭐
- Какие сложности возникают при поддержании списка сегментов при частых выделениях и освобождениях? ⭐⭐
- Как связные списки помогают бороться с внешней фрагментацией (и где они бессильны)? ⭐⭐⭐
- Какие инварианты (правила корректности) должен поддерживать список сегментов, чтобы избежать «потери» памяти? ⭐⭐⭐
- Сравните битовые карты и связные списки по: памяти на метаданные, скорости поиска, удобству слияния свободных областей. ⭐⭐
- Почему битовая карта выигрывает по компактности при малом размере блока, но проигрывает по скорости поиска длинного свободного диапазона? ⭐⭐
- В каких ситуациях связный список будет медленнее битовой карты, и наоборот? ⭐⭐⭐
- Какие типы фрагментации сильнее выражены в подходе «список сегментов», а какие — в подходе «фиксированные блоки»? ⭐⭐⭐

## Алгоритмы выбора «дыры» (First/Next/Best/Worst Fit)

- Опишите идею First Fit и объясните, почему он часто считается практичным компромиссом. ⭐⭐
- В чём смысл Next Fit и почему он может вести себя хуже статистически, несмотря на «локальную оптимизацию»? ⭐⭐
- Почему Best Fit интуитивно кажется хорошим, но на практике часто приводит к большому числу маленьких «бесполезных дыр»? ⭐⭐⭐
- Почему Worst Fit обычно фрагментирует память быстрее ожидаемого? ⭐⭐⭐
- Какие метрики вы бы использовали для сравнения алгоритмов выделения? ⭐⭐
- Как поведение алгоритмов меняется, если запросы памяти имеют «типовые размеры» (например, часто 4К/8К/16К)? ⭐⭐
- Придумайте пример последовательности выделений/освобождений, где Best Fit даст хуже результат, чем First Fit. ⭐⭐⭐
- Придумайте пример, где First Fit создаёт неблагоприятную фрагментацию, а другой алгоритм справляется лучше. ⭐⭐⭐
- Почему алгоритмы «локально оптимальные» (Best Fit) могут быть «глобально плохими» в долгой работе системы? ⭐⭐⭐
- Зачем разделять структуры учёта на «список процессов» и «список дыр», и какие операции это ускоряет? ⭐⭐
- Почему сортировка списка дыр по размеру ускоряет Best Fit и сближает его по скорости с First Fit? ⭐⭐
- Какие новые проблемы появляются, если список дыр сортируется по размеру (а не по адресу)? ⭐⭐⭐
- Почему хранение метаданных прямо внутри «дыры» (размер + ссылка) удобно, и какие риски/ограничения у этого подхода? ⭐⭐
- Объясните идею Quick Fit и почему он особенно хорош для часто повторяющихся размеров запросов. ⭐⭐
- Почему в Quick Fit усложняется слияние свободных областей и растёт фрагментация? ⭐⭐⭐
- В каких типах систем Quick Fit может быть оправдан (и где он опасен)? ⭐⭐⭐

## Виртуальная память

- Какие проблемы остаются нерешёнными при base/limit, даже если изоляция процессов уже есть? ⭐⭐
- Почему рост размеров программ и желание держать «десятки программ открытыми» приводит к необходимости виртуальной памяти? ⭐⭐
- Чем swapping принципиально отличается от виртуальной памяти с точки зрения гранулярности перемещения данных? ⭐⭐
- Почему важно, что виртуальная память позволяет не блокировать систему целиком на долгих I/O-операциях (в сравнении с «грубыми» схемами)? ⭐⭐⭐
- Что такое overlays и почему в 1960-х их делали вручную? ⭐⭐
- Какие типичные ошибки возникали при ручном разбиении программы на overlays и управлении их подгрузкой? ⭐⭐⭐
- Почему overlays замедляли разработку и сопровождение программ, даже если экономили память? ⭐⭐
- Какие идеи overlays «перекочевали» в современную виртуальную память, но уже автоматизированно? ⭐⭐⭐
- Сформулируйте идею виртуальной памяти: что именно является «иллюзией» и за счёт чего она создаётся? ⭐⭐
- Почему деление адресного пространства на страницы фиксированного размера упрощает управление памятью? ⭐⭐
- Как MMU участвует в преобразовании виртуального адреса в физический, и почему без аппаратной поддержки это было бы слишком медленно? ⭐⭐⭐
- Что такое **page frame** и почему он должен быть того же размера, что и страница? ⭐⭐
- Объясните механизм **page fault**: что его вызывает и какие шаги выполняет ОС после возникновения. ⭐⭐⭐
- Почему виртуальная память позволяет запускать программы, размер которых больше физической RAM? ⭐⭐
- Почему виртуальная память обычно эффективнее swapping: в чём выигрыш по времени и по использованию памяти? ⭐⭐

## Устройство вирутальной памяти

- Почему виртуальный адрес логично делить на «номер страницы» и «смещение», и что делает каждую часть? ⭐⭐
- Как вычисляется физический адрес после того, как найден номер физического фрейма? ⭐⭐
- Какие ошибки проектирования могут возникать, если выбрать «слишком маленький» или «слишком большой» размер страницы? ⭐⭐⭐
- Что хранит таблица страниц и почему она является ключевой структурой виртуальной памяти? ⭐⭐
- Какие поля обычно есть в Page Table Entry (PTE) и зачем нужны: Present, Protection, Supervisor/User, Modified, Referenced? ⭐⭐⭐
- Почему биты Modified и Referenced особенно важны для политики замещения страниц? ⭐⭐⭐
- Объясните, как таблица страниц обеспечивает защиту: почему пользовательский процесс не может читать/писать страницы ядра. ⭐⭐⭐
- Почему многие ОС оставляют область около адреса 0 неотображённой (например, старт с 0x1000), и какие ошибки это помогает ловить? ⭐⭐
- Почему «одна плоская таблица страниц» становится неприемлемой в 64-битных адресных пространствах? ⭐⭐
- Объясните принцип многоуровневой таблицы страниц: почему «неиспользуемые подтаблицы не создаются» и как это экономит память. ⭐⭐⭐
- Почему многоуровневость увеличивает число обращений к памяти при трансляции адреса, и как TLB уменьшает эту цену? ⭐⭐⭐
- Какие последствия для производительности даёт промах TLB (TLB miss) и почему переключение контекста связано с TLB? ⭐⭐⭐

Ниже — **70 открытых экзаменационных вопросов** по лекции **«Управление памятью»** (фокус: переход к виртуальной памяти, включение paging на x86, многоядерность, TLB, shootdown, fault-и, IPT и Radix). После каждого вопроса — сложность ⭐ / ⭐⭐ / ⭐⭐⭐.

## Переход от физических адресов к виртуальным

- Почему ОС не может «просто включить виртуальную память» без предварительной подготовки структур данных? ⭐⭐
- Какие практические проблемы возникают, если процессор до включения paging продолжает исполнять код, но адреса уже интерпретируются иначе? ⭐⭐⭐
- Что меняется в модели исполнения программы, когда «все обращения к памяти становятся виртуальными»? ⭐⭐
- Почему переход к виртуальной памяти считается «точкой невозврата» в ранней загрузке ОС? ⭐⭐
- Какие минимальные условия должны быть выполнены, чтобы переход в виртуальный режим не привёл к мгновенному краху системы? ⭐⭐⭐
- Опишите пошагово, как ОС готовит таблицу страниц **до** включения paging и почему она должна содержать **физические** адреса. ⭐⭐⭐
- Почему в CR3 содержится физический, а не виртуальный адрес? ⭐⭐
- Что означает установка бита PG в CR0 и как это меняет путь адреса от инструкции до памяти? ⭐⭐
- Какие ошибки проектирования таблицы страниц чаще всего приводят к падению сразу после включения PG? ⭐⭐⭐
- Зачем в ранней фазе загрузки нужен минимальный набор отображений страниц, даже если позже карта памяти будет совсем другой? ⭐⭐
- Как бы вы объяснили смысл identity mapping человеку, который знает только «виртуальные адреса — это иллюзия»? ⭐⭐
- Почему identity mapping часто рассматривают как «мост» между физическим и виртуальным миром, и какие свойства у этого моста? ⭐⭐⭐

## Что происходит аппаратно при включении paging: pipeline flush и очистка TLB

- Почему при включении paging процессор выполняет **pipeline flush**, и что именно было бы «опасным» без этого шага? ⭐⭐⭐
- Каким образом уже декодированные инструкции в конвейере могут стать некорректными после смены модели адресации? ⭐⭐⭐
- Почему при включении paging очищается TLB, и какие последствия были бы, если бы старые трансляции сохранились? ⭐⭐
- Объясните, почему «следующая инструкция выполняется уже по виртуальному адресу» и какие гарантии нужны, чтобы она действительно была доступна. ⭐⭐⭐
- Какие дополнительные аппаратные события (кроме TLB flush и pipeline flush) вы ожидаете при переходе в новый режим памяти? ⭐⭐⭐
- Какие страницы ОС обязательно должна отобразить identity-mapping’ом, чтобы «не потерять себя» после включения paging? ⭐⭐⭐
- Почему page fault сразу после включения paging особенно опасен, и как identity mapping помогает его избежать? ⭐⭐
- Какие недостатки и риски несёт слишком долгоживущий identity mapping (если его не убрать вовремя)? ⭐⭐⭐
- Почему после успешного старта ОС обычно меняет схему отображения (kernel space / user space) и избавляется от временной карты? ⭐⭐

## Виртуальная память в многоядерных системах

- Почему у каждого ядра свой набор управляющих регистров (CR0/CR3/IDTR и др.), и какие преимущества это даёт ОС? ⭐⭐
- Как возможно, что одно ядро уже работает с PG=1, а другое — ещё с PG=0, и почему это важно при загрузке? ⭐⭐⭐
- Почему paging включается **каждым ядром отдельно**, даже если ОС «одна»? ⭐⭐
- Какие ошибки синхронизации могут возникнуть, если разные ядра имеют «разный взгляд» на память в раннем бутстрапе? ⭐⭐⭐
- Объясните роль bootstrap-ядра (BSP): что именно оно обязано подготовить для остальных ядер, чтобы они стали «равноправными». ⭐⭐⭐- Почему после включения питания активным становится только BSP, а остальные ядра «спят»? ⭐⭐
- Что такое INIT IPI и SIPI, и почему требуется два разных сигнала для пробуждения AP? ⭐⭐
- Почему адрес старта AP (в SIPI) должен быть < 1 МБ и как это связано с реальным режимом? ⭐⭐⭐
- Какие задачи должен выполнить BSP до пробуждения AP, чтобы те могли корректно стартовать? ⭐⭐
- Что произойдёт, если AP начнёт исполнять код без корректно настроенного стека? ⭐⭐⭐
- Опишите, в каком режиме находится AP сразу после SIPI и как формируется адресация в этот момент (Segment*16+Offset). ⭐⭐
- Почему у AP после пробуждения paging отключён и что это означает для доступа к памяти и коду загрузчика? ⭐⭐
- Какие шаги должен выполнить bootstrap-код AP, чтобы привести ядро к общему «режиму ОС» (protected mode + paging)? ⭐⭐⭐
- Почему bootstrap-код AP обычно размещают в низкой памяти (например, 0x7000–0x8000)? ⭐⭐
- Как вы организовали бы синхронизацию AP с BSP: какие флаги/барьеры/соглашения нужны, чтобы избежать гонок? ⭐⭐⭐
- Почему «после инициализации все ядра равноправны», и что остаётся общим ресурсом, несмотря на независимость регистров? ⭐⭐

## Переключение адресных пространств, кеши и безопасность

- Почему при смене CR3 сбрасывается TLB, но не обязательно сбрасываются L1/L2/L3 кеши? ⭐⭐⭐
- Чем полезно то, что кеши работают по физическим адресам, и какой «неочевидный минус» это создаёт для безопасности? ⭐⭐⭐
- Объясните принцип, как измерение времени доступа к данным в кеше может приводить к утечкам (на уровне идеи, без деталей конкретных атак). ⭐⭐⭐
- Почему даже «простая» операция смены CR3 может влиять на безопасность всей системы? ⭐⭐
- Зачем нужны техники вроде PCID/ASID, барьеры спекуляции и изоляция таблиц страниц ядра, если смотреть на проблему со стороны памяти и кешей? ⭐⭐⭐
- Почему многоуровневые таблицы страниц делают трансляцию адресов слишком медленной без дополнительного ускорения? ⭐⭐
- Что именно кэширует TLB и почему это «кэш другого типа», чем L1/L2 для данных? ⭐⭐
- Объясните разницу между TLB hit и TLB miss и их влияние на латентность каждого обращения к памяти. ⭐⭐
- Как устройство TLB как ассоциативного кеша влияет на скорость поиска и на стоимость промахов? ⭐⭐⭐
- Зачем разделять TLB для инструкций и данных (ITLB/DTLB), и какие преимущества/сложности это даёт? ⭐⭐
- Какие факторы в программе увеличивают вероятность TLB miss (паттерны доступа, размер working set, размер страниц)? ⭐⭐⭐
- Чем отличается hardware-managed TLB от software-managed, и почему это влияет на дизайн ядра ОС? ⭐⭐⭐
- Какие преимущества даёт hardware-managed подход (например, x86) с точки зрения простоты ОС, и какие минусы возможны? ⭐⭐
- Какие преимущества даёт software-managed подход (например, MIPS/SPARC) для контроля и оптимизаций ОС? ⭐⭐⭐
- Почему после заполнения TLB команда «повторяется», и какие свойства архитектуры делают это корректным? ⭐⭐⭐

## TLB и переключение контекста: flush, ASID/PCID, многоуровневые TLB

- Почему при переключении процесса «чужие записи» в TLB становятся опасными или бессмысленными? ⭐⭐
- Какие издержки у полной очистки TLB при каждом контекстном переключении и как это отражается на производительности? ⭐⭐
- Объясните идею ASID/PCID: как маркировка записей позволяет не очищать TLB полностью. ⭐⭐⭐
- Почему многоуровневые TLB (L1/L2) похожи на многоуровневые кеши, но решают отдельную задачу? ⭐⭐
- Какие сценарии приводят к тому, что даже большой L2 TLB не спасает производительность? ⭐⭐⭐
- Почему изменения в PTE «не отражаются мгновенно», и что именно продолжает использовать процессор? ⭐⭐
- Объясните, почему TLB хранит не только физический адрес, но и права доступа, и как это влияет на безопасность при смене разрешений. ⭐⭐⭐
- Почему правило «делать PTE менее разрешающим без flush нельзя» критично? Приведите логическое обоснование. ⭐⭐⭐
- Зачем нужен барьер памяти (mfence) между записью нового PTE и инвалидацией TLB? ⭐⭐⭐
- В чём отличие точечной инвалидации (invlpg) от глобальной (mov cr3, cr3) и как выбрать правильную стратегию? ⭐⭐
- Почему в многоядерной системе инвалидация TLB должна выполняться на **всех** ядрах, где могла кэшироваться страница? ⭐⭐⭐
- Объясните механизм TLB shootdown: зачем нужны IPI и подтверждения от ядер. ⭐⭐⭐
- Почему нельзя переиспользовать физический фрейм до завершения shootdown, даже если «мы уже обновили PTE»? ⭐⭐⭐
- Почему обработчик page fault сам подвержен риску page fault, и какие ресурсы ему критически нужны (стек, таблицы, буферы)? ⭐⭐⭐
- Что такое double fault (в смысле «исключение во время обработки исключения») и почему он часто заканчивается фатально для системы? ⭐⭐⭐
- Какие практики ОС используются, чтобы избежать page fault внутри обработчика (pinning/wired pages, prefaulting, отдельные пулы)? ⭐⭐⭐
- Почему разделение пулов страниц ядра и пользователя снижает вероятность катастрофических сбоев при вытеснении? ⭐⭐⭐

## Инвертированные таблицы страниц (IPT) и Radix Page Tables: эволюция масштабируемости

- Почему классические таблицы страниц начинают занимать «слишком много памяти» при больших виртуальных пространствах? ⭐⭐
- В чём идея inverted page table: что считается «ключом поиска» и почему запись соответствует физическому фрейму? ⭐⭐⭐
- Какие трудности создаёт поиск по хешу (коллизии, синхронизация) и почему это плохо для аппаратной реализации? ⭐⭐⭐
- Почему IPT со временем стали менее актуальны: какие технологические/архитектурные изменения «сдвинули баланс»? ⭐⭐
- Что такое Radix Page Tables как структура (radix tree) и чем она концептуально похожа на обычные многоуровневые таблицы? ⭐⭐
- Почему динамическая настраиваемая глубина дерева в Radix может быть преимуществом для больших систем? ⭐⭐⭐
- В чём идея выигрыша Radix в виртуализации по сравнению с подходами, где требуется «два обхода» таблиц? ⭐⭐⭐
- Почему при TLB hit производительность почти одинакова, а разница проявляется при TLB miss и в виртуализации? ⭐⭐
- Как поддержка разных размеров страниц влияет на эффективность TLB и на глубину обхода таблиц? ⭐⭐⭐
- Почему эволюция от hashed/IPT к radix/иерархиям считается «общим направлением» развития MMU? ⭐⭐⭐

Ниже — **65 открытых экзаменационных вопросов** по лекции **«Алгоритмы замещения страниц»** (≥50), **разделённых по темам**. После каждого вопроса — сложность ⭐ / ⭐⭐ / ⭐⭐⭐.

## Основы замещения страниц и цели политики

- Что происходит в ОС при page fault и почему почти всегда требуется освободить фрейм под новую страницу? ⭐⭐
- Чем принципиально отличается выселение **dirty**-страницы от **clean**-страницы с точки зрения стоимости? ⭐⭐
- Какие метрики вы бы использовали, чтобы оценивать «качество» алгоритма замещения страниц (не только число page faults)? ⭐⭐⭐
- Почему «минимизировать page faults» не всегда означает «минимизировать время выполнения»? ⭐⭐⭐
- Объясните феномен thrashing: как он связан с неудачным выбором жертвы и с рабочим множеством процесса? ⭐⭐⭐
- Какие системные сигналы (кроме page fault) могут подсказать ОС, что память перегружена и политика вытеснения работает плохо? ⭐⭐⭐
- Почему случайное замещение страниц обычно даёт плохие результаты, даже если кажется «справедливым»? ⭐⭐
- Приведите пример паттерна обращений, при котором случайный выбор почти гарантированно вызывает повторные page faults. ⭐⭐⭐
- Какие свойства поведения программ (локальность, фазы) делают задачу замещения принципиально предсказуемой? ⭐⭐
- Почему при одинаковом объёме памяти два разных приложения могут радикально отличаться по частоте page faults? ⭐⭐

## Алгоритмы Optimal Page Replacement и NRU

- В чём идея OPT и почему он «идеален» с точки зрения числа page faults? ⭐⭐
- Почему OPT нереализуем в реальной ОС, но всё равно полезен на практике? ⭐⭐
- Как можно смоделировать OPT на трассе обращений и что это даёт исследователю/инженеру? ⭐⭐
- Почему сравнение с OPT важно именно как «верхняя граница», а не как рецепт реализации? ⭐⭐
- Что означает утверждение «если алгоритм хуже OPT на 1–2%, то он почти оптимален» — и когда это может быть неверно? ⭐⭐⭐
- На последовательности обращений `[1,2,3,4,1,2,5,1,2,3,4,5]` объясните логику выбора жертвы OPT при памяти на 3 страницы (не обязательно считать все шаги, важен принцип). ⭐⭐⭐
- Какие данные о странице отражают биты **R (Referenced)** и **M (Modified)**, и почему их достаточно для базовой эвристики? ⭐⭐
- Зачем ОС периодически сбрасывает R-бит и почему выбор периода (например, 20 мс) влияет на качество алгоритма? ⭐⭐⭐
- Объясните 4 класса NRU (R/M) и почему именно такой приоритет обычно рационален. ⭐⭐
- Почему NRU выбирает случайную страницу внутри класса, и чем это полезно с точки зрения накладных расходов? ⭐⭐
- В каких сценариях NRU может вести себя плохо из-за того, что не различает «давно» и «совсем недавно»? ⭐⭐⭐
- Как изменится поведение NRU, если система слишком редко сбрасывает R-биты? А если слишком часто? ⭐⭐⭐
- Как можно реализовать/эмулировать R и M, если аппаратных битов нет? Почему это может быть дорого? ⭐⭐⭐
- Почему M-бит обычно не сбрасывают периодически, в отличие от R? ⭐⭐

## Алгоритмы FIFO и Second Chance

- Как FIFO выбирает жертву и почему он почти не требует вычислений? ⭐⭐
- В чём ключевой недостаток FIFO с точки зрения «актуальности» страниц? ⭐⭐
- Объясните аномалию Белади: почему увеличение числа фреймов может увеличить число page faults именно у FIFO? ⭐⭐⭐
- Приведите интуитивный пример (без строгого доказательства), как FIFO может вытеснить «полезную» страницу просто потому, что она старая. ⭐⭐
- Почему FIFO полезен как учебный алгоритм и как базовая линия для сравнения, но редко используется «в чистом виде»? ⭐⭐
- Как Second Chance модифицирует FIFO и какую проблему FIFO он решает? ⭐⭐
- Что происходит со страницей, у которой R=1, когда она рассматривается как кандидат на вытеснение? ⭐⭐
- Почему Second Chance можно считать «мягкой» версией NRU? ⭐⭐
- В каких условиях Second Chance вырождается по поведению почти в FIFO? ⭐⭐
- Какие накладные расходы появляются у Second Chance по сравнению с FIFO и от чего они зависят? ⭐⭐⭐

## Алгоритмы Clock и Enhanced Clock

- Почему Clock называют оптимизацией Second Chance и что именно оптимизируется (структуры данных/операции)? ⭐⭐
- Опишите роль «стрелки» в Clock: что она обозначает и как движется при page fault? ⭐⭐
- Почему Clock обычно проще масштабируется, чем вариант с реальной очередью FIFO и перемещением элементов? ⭐⭐
- Разберите пример: если у страниц A,B,C,D биты R = 1,1,0,1 и стрелка указывает на A — как Clock найдёт жертву? ⭐⭐⭐
- В каких нагрузках Clock особенно хорош, а в каких может оказаться недостаточно точным? ⭐⭐⭐
- Почему Clock так часто используется в реальных ОС (с точки зрения «цена/качество»)? ⭐⭐
- Как Enhanced Clock использует M-бит и почему это уменьшает число дорогих операций записи на диск? ⭐⭐⭐
- Чем Enhanced Clock концептуально похож на NRU и чем отличается на уровне «процесса поиска жертвы»? ⭐⭐
- Что даёт Two-Handed Clock по сравнению с обычным Clock: какую проблему точности он решает? ⭐⭐⭐
- Почему «две стрелки» позволяют лучше оценить, что страница действительно не использовалась достаточно долго? ⭐⭐⭐
- В каких сценариях Two-Handed Clock может дать заметный выигрыш, а где усложнение не оправдается? ⭐⭐⭐

## Алгоритмы LRU и NFU

- На каком предположении о поведении программ основан LRU и как это связано с локальностью? ⭐⭐
- Почему LRU часто рассматривают как практическое приближение OPT (интуиция «прошлое предсказывает будущее»)? ⭐⭐
- Как выглядела бы «идеальная» реализация LRU с глобальным счётчиком/временем и что в ней дорого? ⭐⭐⭐
- Почему чистый LRU редко реализуется напрямую в ОС без специальных аппаратных механизмов? ⭐⭐⭐
- На последовательности обращений `1,2,3,1,4,2,1,5` объясните принцип выбора жертвы LRU при 3 фреймах (важна логика, не обязательно полная таблица). ⭐⭐⭐
- Как работает NFU и какую «идею» (частота/популярность) он пытается использовать? ⭐⭐
- Почему NFU может сохранять страницы, которые были важны в прошлом, но больше не нужны? ⭐⭐⭐
- Как фазовое поведение программы (например, компилятор) может «сломать» NFU? ⭐⭐⭐
- Какие способы «забывания прошлого» вы могли бы предложить для улучшения NFU? ⭐⭐⭐

## Алгоритмы Aging и Working Set

- Опишите механизм Aging: сдвиг счётчика, добавление R в старший бит, сброс R. ⭐⭐
- Почему Aging лучше NFU имитирует LRU и как именно он «забывает» старые обращения? ⭐⭐
- От чего зависит точность Aging (размер счётчика, период тика) и какие компромиссы при выборе параметров? ⭐⭐⭐
- Почему Aging не различает порядок обращений внутри одного интервала, и когда это важно? ⭐⭐⭐
- Объясните, почему на практике часто достаточно 8-битного счётчика (с точки зрения «длины истории»). ⭐⭐
- Дайте определение рабочего множества W(k,t) и объясните смысл параметра окна (k или Δ). ⭐⭐
- Почему рабочее множество «меняется медленно» и как это связано с фазами выполнения программы? ⭐⭐
- Как алгоритм Working Set решает, что страница «вышла» из рабочего множества? Какие данные ему нужны? ⭐⭐⭐
- Почему Working Set помогает предотвращать thrashing на уровне всей системы, а не только одного процесса? ⭐⭐⭐
- Что такое prepaging и почему знание рабочего множества делает его возможным? ⭐⭐

## Алгоритмы WSClock и гибридные алгоритмы

- В чём ключевая идея WSClock и почему он считается удачным компромиссом точности и скорости? ⭐⭐⭐
- Какие поля хранит запись о странице в WSClock (R, M, время последнего использования) и зачем каждое нужно? ⭐⭐
- Что происходит, если WSClock находит «старую» страницу, но она dirty? Почему важна асинхронная запись? ⭐⭐⭐
- Опишите два сценария после полного обхода круга WSClock: когда были назначены записи и когда нет. ⭐⭐⭐
- Почему WSClock обычно уменьшает I/O по сравнению с простыми схемами, даже при высокой нагрузке? ⭐⭐⭐
- Почему современные ОС почти никогда не используют «чистые» алгоритмы, а строят гибриды (Clock/LRU/Working Set)? ⭐⭐⭐
- Зачем Linux разделяет страницы на файловые и анонимные (split LRU), и почему их нужно вытеснять по-разному? ⭐⭐⭐
- Как бы вы объяснили, почему политика замещения страниц тесно связана с подсистемой ввода-вывода и кэшированием файлов? ⭐⭐⭐
- Какие компромиссы возникают между справедливостью между процессами и глобальной оптимизацией page faults? ⭐⭐⭐
- Как бы вы спроектировали эксперимент, чтобы честно сравнить FIFO, Clock, Aging и WSClock на одной рабочей нагрузке? ⭐⭐⭐

